{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Notice**  \n",
    "1. For data of volume, **Bitcon** data is incomplete, so we chose to eliminate the Bitcon in the volume section, and chose to plot the volume graph in the next place in the tvl order sort, i.e., the **Polygon**.  \n",
    "2. For the chainname obtained through the tvl sort is not completely correct, in the api of the fee and volume there are some chains can not get the data, we are here to eliminate these data.  \n",
    "3. We need data of 150 days to calculate the z-score to recognize abnormal values. We only plot data of 120 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name           tvl\n",
      "15   Ethereum  7.689544e+10\n",
      "47     Solana  9.401312e+09\n",
      "92       Tron  9.025371e+09\n",
      "8         BSC  5.820793e+09\n",
      "12       Base  3.923212e+09\n",
      "54    Bitcoin  3.588940e+09\n",
      "17   Arbitrum  3.340990e+09\n",
      "95        Sui  1.747100e+09\n",
      "16  Avalanche  1.588138e+09\n",
      "58      Aptos  1.263606e+09\n",
      "18    Polygon  1.175651e+09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# you can get the chain list straihgt from the API\n",
    "url = 'https://api.llama.fi/v2/chains'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200: # data was fetched successfully\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    raise Exception('Error fetching data from DeFiLlama API')\n",
    "\n",
    "dex_all_chains_url = \"https://api.llama.fi/overview/dexs?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyVolume\"\n",
    "dex_all_chains_response = requests.get(dex_all_chains_url)\n",
    "\n",
    "dex_all_chains_data = dex_all_chains_response.json()\n",
    "dex_all_chains = set(dex_all_chains_data.get('allChains', []))\n",
    "\n",
    "\n",
    "fees_all_chains_url = \"https://api.llama.fi/overview/fees?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyFees\"\n",
    "fees_all_chains_response = requests.get(fees_all_chains_url)\n",
    "\n",
    "fees_all_chains_data = fees_all_chains_response.json()\n",
    "fees_all_chains = set(fees_all_chains_data.get('allChains', []))\n",
    "\n",
    "common_chains = dex_all_chains.intersection(fees_all_chains) # get the common chains between the two sets\n",
    "\n",
    "df = df[['name', 'tvl']]\n",
    "df = df[df['name'].isin(common_chains)]\n",
    "\n",
    "# Sort the data to get the top 10 chains by TVL\n",
    "df = df.sort_values(by='tvl', ascending=False).head(11)\n",
    "print(df)\n",
    "\n",
    "base_folder = './data'\n",
    "fee_folder = os.path.join(base_folder, 'fee')\n",
    "tvl_folder = os.path.join(base_folder, 'tvl')\n",
    "volume_folder = os.path.join(base_folder, 'volume')\n",
    "price_folder = os.path.join(base_folder, 'price')\n",
    "coin_folder = os.path.join(base_folder, 'coin')\n",
    "\n",
    "# for folder in [fee_folder, tvl_folder, volume_folder, price_folder, coin_folder]:\n",
    "#     if os.path.exists(folder):\n",
    "#         shutil.rmtree(folder)  # delete the folder and its contents\n",
    "#     os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_order = df['name'].tolist()\n",
    "chain_index = {chain: str(index + 1).zfill(2) for index, chain in enumerate(chain_order)}\n",
    "# give chainname an index so we can plot in order\n",
    "\n",
    "\n",
    "def fetch_historical_data(chain_name, metric):\n",
    "    if metric == 'tvl':\n",
    "        url = f'https://api.llama.fi/v2/historicalChainTvl/{chain_name}'\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)  # Directly create DataFrame from the list of dictionaries\n",
    "            df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "            csv_filename = os.path.join(tvl_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'volume':\n",
    "        url = (f'https://api.llama.fi/overview/dexs/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyVolume')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            csv_filename = os.path.join(volume_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'fee':\n",
    "        url = (f'https://api.llama.fi/overview/fees/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyFees')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            csv_filename = os.path.join(fee_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "    else:\n",
    "        raise ValueError('Invalid metric specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "# find a way to use relative path, so that the function in dynamoUtil can be run in any machine\n",
    "src_path = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common\\src'\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "USER = getpass.getuser()\n",
    "REPO_PATH = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common'\n",
    "\n",
    "sys.path.append(REPO_PATH)\n",
    "sys.path.append(REPO_PATH + '/src')\n",
    "\n",
    "from dynamoUtil import price_bar_query\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "mapping = {\n",
    "    'Ethereum': 'ETHUSDT-OKX-00000000-FUT',\n",
    "    'Tron': 'TRXUSDT-OKX-00000000-FUT',\n",
    "    'Solana': 'SOLUSDT-OKX-00000000-FUT',\n",
    "    'BSC': 'BNBUSDT-OKX-00000000-FUT',\n",
    "    'Base': 'BASEUSDT-OKX-00000000-FUT',\n",
    "    'Bitcoin': 'BTCUSDT-OKX-00000000-FUT',\n",
    "    'Arbitrum': 'ARBUSDT-OKX-00000000-FUT',\n",
    "    'Avalanche': 'AVAXUSDT-OKX-00000000-FUT',\n",
    "    'Sui': 'SUIUSDT-OKX-00000000-FUT',\n",
    "    'Aptos': 'APTUSDT-OKX-00000000-FUT',\n",
    "    'Polygon': 'MATICUSDT-OKX-00000000-FUT'\n",
    "}\n",
    "\n",
    "# give df the mapping of the code\n",
    "'''\n",
    "    这里有个问题，我用的是比较生硬的map，如果有新的chain，就需要手动添加，这个可以通过API来解决？\n",
    "'''\n",
    "\n",
    "def fetch_price_data(chain_name):\n",
    "    today = datetime.now().replace(hour=23, minute=0, second=0, microsecond=0)\n",
    "    start_date = today - timedelta(days=120)\n",
    "\n",
    "    today_str = today.strftime('%Y-%m-%d-%H-%M')\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d-%H-%M')\n",
    "    \n",
    "    instrument_code = mapping.get(chain_name)\n",
    "\n",
    "    price_data = price_bar_query(instrument_code + '|1440', start_date_str, today_str, 'live')\n",
    "    price_df = pd.DataFrame(price_data)\n",
    "    print(f\"Columns in DataFrame for {chain_name}: {price_df.columns}\") \n",
    "    print(price_df.head())\n",
    "    \n",
    "    if price_df.empty:\n",
    "        print(f\"No valid data found for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    if 'timestamp' not in price_df.columns or 'close' not in price_df.columns:\n",
    "        print(f\"Required columns 'timestamp' or 'close' not found in the data for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    selected_columns = price_df[['timestamp', 'close']].copy()\n",
    "\n",
    "    selected_columns['timestamp'] = pd.to_datetime(selected_columns['timestamp']).dt.date\n",
    "\n",
    "    selected_columns.rename(columns={'timestamp': 'date', 'close': 'price'}, inplace=True)\n",
    "\n",
    "    csv_filename = os.path.join(price_folder, f\"{chain_index[chain_name]}_{chain_name}_price.csv\")\n",
    "    # csv_filename = os.path.join(price_folder_USD, f\"{chain_index[chain_name]}_{chain_name}_price_USD.csv\")\n",
    "    selected_columns.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved price data for {chain_name} to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.For tvl we store all 11 of them.  \n",
    "2.For volume we skip Bitcoin, it's incomplete.  \n",
    "3.For fee we store all 11 of them.\n",
    "4.For price we skip Base(doesn't have coin), store POL and TRX using api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame for Ethereum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open              volume     high  \\\n",
      "0  2552.22  1723334106487 2024-08-09  2666.44  21454401.900000002  2709.05   \n",
      "1  2580.24  1723420725412 2024-08-10  2584.56   8067897.700000001  2643.88   \n",
      "2  2539.61  1723507068141 2024-08-11   2624.5  19454525.599999998     2720   \n",
      "3  2516.11  1723593333740 2024-08-12   2537.4  26554924.000000004  2751.96   \n",
      "4     2607  1723679928878 2024-08-13  2718.39  18332897.600000005  2738.44   \n",
      "\n",
      "     close                instrument  \n",
      "0  2598.71  ETHUSDT-OKX-00000000-FUT  \n",
      "1  2610.31  ETHUSDT-OKX-00000000-FUT  \n",
      "2  2555.82  ETHUSDT-OKX-00000000-FUT  \n",
      "3  2722.53  ETHUSDT-OKX-00000000-FUT  \n",
      "4  2702.53  ETHUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Ethereum to ./data\\price\\01_Ethereum_price.csv\n",
      "Columns in DataFrame for Solana: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open              volume    high  \\\n",
      "0  150.64  1723334222062 2024-08-09  161.22   8530487.879999999  161.99   \n",
      "1  152.65  1723420493650 2024-08-10  154.92          3713932.02   156.5   \n",
      "2  140.94  1723507184247 2024-08-11  154.69   8782868.469999999     158   \n",
      "3  141.78  1723593449489 2024-08-12  142.69  11303254.629999999  150.77   \n",
      "4  142.91  1723679697247 2024-08-13  146.66          6148844.78  149.83   \n",
      "\n",
      "    close                instrument  \n",
      "0  156.28  SOLUSDT-OKX-00000000-FUT  \n",
      "1  154.03  SOLUSDT-OKX-00000000-FUT  \n",
      "2  141.52  SOLUSDT-OKX-00000000-FUT  \n",
      "3  146.32  SOLUSDT-OKX-00000000-FUT  \n",
      "4  146.62  SOLUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Solana to ./data\\price\\02_Solana_price.csv\n",
      "Columns in DataFrame for Tron: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Tron. Skipping.\n",
      "Columns in DataFrame for BSC: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "     low      updatedAt  timestamp   open    volume   high  close  \\\n",
      "0  498.6  1723334327455 2024-08-09  513.9   6604909  516.2  508.8   \n",
      "1  507.4  1723420599081 2024-08-10    508   4651664  525.3  523.1   \n",
      "2  502.1  1723506941779 2024-08-11  526.2   9302437  535.9  503.5   \n",
      "3  499.2  1723593554657 2024-08-12  505.5  11402768  524.1  518.6   \n",
      "4  512.7  1723679802511 2024-08-13    521  12435943  527.5    524   \n",
      "\n",
      "                 instrument  \n",
      "0  BNBUSDT-OKX-00000000-FUT  \n",
      "1  BNBUSDT-OKX-00000000-FUT  \n",
      "2  BNBUSDT-OKX-00000000-FUT  \n",
      "3  BNBUSDT-OKX-00000000-FUT  \n",
      "4  BNBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for BSC to ./data\\price\\04_BSC_price.csv\n",
      "Columns in DataFrame for Base: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Base. Skipping.\n",
      "Columns in DataFrame for Bitcoin: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open              volume     high  \\\n",
      "0  59522.1  1723334337981 2024-08-09  61212.9          12304663.1  61574.7   \n",
      "1  60241.2  1723420609598 2024-08-10  60550.2           3666225.2    61250   \n",
      "2  58272.4  1723506952280 2024-08-11  61089.7           8409915.8  61951.3   \n",
      "3    57610  1723593565276 2024-08-12  58458.1          15152629.5  60718.8   \n",
      "4    58366  1723679813023 2024-08-13    59787  10675324.799999999  61589.4   \n",
      "\n",
      "     close                instrument  \n",
      "0    60842  BTCUSDT-OKX-00000000-FUT  \n",
      "1  60919.5  BTCUSDT-OKX-00000000-FUT  \n",
      "2  58727.7  BTCUSDT-OKX-00000000-FUT  \n",
      "3  59348.6  BTCUSDT-OKX-00000000-FUT  \n",
      "4  60591.9  BTCUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Bitcoin to ./data\\price\\06_Bitcoin_price.csv\n",
      "Columns in DataFrame for Arbitrum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open              volume    high  \\\n",
      "0  0.5356  1723334295863 2024-08-09  0.5507   8889217.499999998  0.5896   \n",
      "1  0.5606  1723420567451 2024-08-10  0.5748           5061782.9  0.5908   \n",
      "2  0.5481  1723506910057 2024-08-11  0.5791           5665718.7  0.5973   \n",
      "3  0.5452  1723593523124 2024-08-12  0.5522   5638156.199999999  0.5971   \n",
      "4  0.5659  1723679770953 2024-08-13  0.5877  3438359.6999999997  0.5901   \n",
      "\n",
      "    close                instrument  \n",
      "0  0.5772  ARBUSDT-OKX-00000000-FUT  \n",
      "1  0.5773  ARBUSDT-OKX-00000000-FUT  \n",
      "2  0.5523  ARBUSDT-OKX-00000000-FUT  \n",
      "3  0.5891  ARBUSDT-OKX-00000000-FUT  \n",
      "4  0.5787  ARBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Arbitrum to ./data\\price\\07_Arbitrum_price.csv\n",
      "Columns in DataFrame for Sui: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open     volume    high   close  \\\n",
      "0  0.8244  1723334232565 2024-08-09  0.8486  215881869  0.8796  0.8558   \n",
      "1  0.8478  1723420504173 2024-08-10   0.858  252428240   0.966  0.9194   \n",
      "2  0.8584  1723507194813 2024-08-11  0.9132  242064476  0.9307  0.8738   \n",
      "3  0.8881  1723593459979 2024-08-12  0.8979  609816547  1.1198  1.0148   \n",
      "4  0.9304  1723679707769 2024-08-13  1.0026  326118231  1.0067  0.9554   \n",
      "\n",
      "                 instrument  \n",
      "0  SUIUSDT-OKX-00000000-FUT  \n",
      "1  SUIUSDT-OKX-00000000-FUT  \n",
      "2  SUIUSDT-OKX-00000000-FUT  \n",
      "3  SUIUSDT-OKX-00000000-FUT  \n",
      "4  SUIUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Sui to ./data\\price\\08_Sui_price.csv\n",
      "Columns in DataFrame for Avalanche: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open              volume    high  \\\n",
      "0  21.278  1723334306402 2024-08-09  22.664  1736133.2999999998  22.682   \n",
      "1  21.387  1723420577974 2024-08-10  21.599            898613.9  21.884   \n",
      "2  20.377  1723506920594 2024-08-11   21.64  1707252.4000000001  22.376   \n",
      "3  20.449  1723593533653 2024-08-12  20.529  2142315.1999999997  21.715   \n",
      "4   20.59  1723679781480 2024-08-13  21.272             1467507  21.621   \n",
      "\n",
      "    close                 instrument  \n",
      "0  21.744  AVAXUSDT-OKX-00000000-FUT  \n",
      "1  21.581  AVAXUSDT-OKX-00000000-FUT  \n",
      "2  20.403  AVAXUSDT-OKX-00000000-FUT  \n",
      "3  21.259  AVAXUSDT-OKX-00000000-FUT  \n",
      "4   21.38  AVAXUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Avalanche to ./data\\price\\09_Avalanche_price.csv\n",
      "Columns in DataFrame for Aptos: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open    volume    high   close  \\\n",
      "0   5.625  1723334285293 2024-08-09  5.7508   3615070  5.8918   5.746   \n",
      "1  5.6811  1723420556909 2024-08-10  5.7178   5409295  6.3817  6.2736   \n",
      "2  5.7257  1723506899534 2024-08-11  6.2529   3741521  6.2663  5.7263   \n",
      "3  5.7785  1723593512601 2024-08-12  5.7985  11183796  6.8471  6.4372   \n",
      "4  6.1482  1723679760465 2024-08-13  6.4255   6889364  6.9396   6.795   \n",
      "\n",
      "                 instrument  \n",
      "0  APTUSDT-OKX-00000000-FUT  \n",
      "1  APTUSDT-OKX-00000000-FUT  \n",
      "2  APTUSDT-OKX-00000000-FUT  \n",
      "3  APTUSDT-OKX-00000000-FUT  \n",
      "4  APTUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Aptos to ./data\\price\\10_Aptos_price.csv\n",
      "Columns in DataFrame for Polygon: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Polygon. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# for chain_name in df['name']:\n",
    "#     for metric in ['tvl', 'fee']:\n",
    "#         fetch_historical_data(chain_name, metric)\n",
    "        \n",
    "# for chain_name in df['name']:\n",
    "#     if chain_name.lower() == 'bitcoin':\n",
    "#         print(f\"Skipping {chain_name} for {metric}\")\n",
    "#         continue # Skip Bitcoin as its volume data is incomplete\n",
    "#     metric = 'volume'\n",
    "#     fetch_historical_data(chain_name, metric)\n",
    "    \n",
    "for chain_name in df['name']:\n",
    "    fetch_price_data(chain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 03_Tron_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/open-interest/days\"\n",
    "params_trx = {\n",
    "    'market': 'okex', \n",
    "    'instrument': 'TRX-USDT-VANILLA-PERPETUAL', \n",
    "    'groups': 'OHLC',  \n",
    "    'limit': 200,  \n",
    "    'aggregate': 1,  \n",
    "    'fill': 'true',  \n",
    "    'apply_mapping': 'true',  \n",
    "    'api_key': 'YOUR_API_KEY'  \n",
    "}\n",
    "\n",
    "response_trx = requests.get(base_url, params=params_trx)\n",
    "\n",
    "if response_trx.status_code == 200:\n",
    "    data = response_trx.json()\n",
    "\n",
    "    if 'Data' in data and isinstance(data['Data'], list):\n",
    "        data_list = data['Data']\n",
    "        \n",
    "        extracted_data = [{'timestamp': entry['TIMESTAMP'], 'price': entry['CLOSE_QUOTE']}\n",
    "                          for entry in data_list if 'TIMESTAMP' in entry and 'CLOSE_QUOTE' in entry]\n",
    "        \n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            csv_filename = os.path.join(price_folder, f\"03_Tron_price.csv\")\n",
    "            df.tail(120).to_csv(csv_filename, index=False)\n",
    "            print(\"Data saved to 03_Tron_price.csv\")\n",
    "        else:\n",
    "            print(\"No data available for TRX-USDT on OKEx (OKX).\")\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {data}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP status code: {response_trx.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "PermissionError",
     "evalue": "[Errno 13] Permission denied: './data\\\\price\\\\11_Polygon_price.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mPermissionError\u001b[0m                           Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[18], line 32\u001b[0m\n\u001b[0;32m     30\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m df\u001b[38;5;241m.\u001b[39mempty:\n\u001b[0;32m     31\u001b[0m     csv_filename \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mjoin(price_folder, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m11_Polygon_price.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m---> 32\u001b[0m     df\u001b[38;5;241m.\u001b[39mto_csv(csv_filename, index\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[0;32m     33\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mData saved to 11_Polygon_price.csv\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     34\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\pandas\\util\\_decorators.py:333\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[1;34m(*args, **kwargs)\u001b[0m\n\u001b[0;32m    327\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[0;32m    328\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[0;32m    329\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39m_format_argument_list(allow_args)),\n\u001b[0;32m    330\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[0;32m    331\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mfind_stack_level(),\n\u001b[0;32m    332\u001b[0m     )\n\u001b[1;32m--> 333\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m func(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\pandas\\core\\generic.py:3967\u001b[0m, in \u001b[0;36mNDFrame.to_csv\u001b[1;34m(self, path_or_buf, sep, na_rep, float_format, columns, header, index, index_label, mode, encoding, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, decimal, errors, storage_options)\u001b[0m\n\u001b[0;32m   3956\u001b[0m df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(\u001b[38;5;28mself\u001b[39m, ABCDataFrame) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mto_frame()\n\u001b[0;32m   3958\u001b[0m formatter \u001b[38;5;241m=\u001b[39m DataFrameFormatter(\n\u001b[0;32m   3959\u001b[0m     frame\u001b[38;5;241m=\u001b[39mdf,\n\u001b[0;32m   3960\u001b[0m     header\u001b[38;5;241m=\u001b[39mheader,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3964\u001b[0m     decimal\u001b[38;5;241m=\u001b[39mdecimal,\n\u001b[0;32m   3965\u001b[0m )\n\u001b[1;32m-> 3967\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m DataFrameRenderer(formatter)\u001b[38;5;241m.\u001b[39mto_csv(\n\u001b[0;32m   3968\u001b[0m     path_or_buf,\n\u001b[0;32m   3969\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[0;32m   3970\u001b[0m     sep\u001b[38;5;241m=\u001b[39msep,\n\u001b[0;32m   3971\u001b[0m     encoding\u001b[38;5;241m=\u001b[39mencoding,\n\u001b[0;32m   3972\u001b[0m     errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m   3973\u001b[0m     compression\u001b[38;5;241m=\u001b[39mcompression,\n\u001b[0;32m   3974\u001b[0m     quoting\u001b[38;5;241m=\u001b[39mquoting,\n\u001b[0;32m   3975\u001b[0m     columns\u001b[38;5;241m=\u001b[39mcolumns,\n\u001b[0;32m   3976\u001b[0m     index_label\u001b[38;5;241m=\u001b[39mindex_label,\n\u001b[0;32m   3977\u001b[0m     mode\u001b[38;5;241m=\u001b[39mmode,\n\u001b[0;32m   3978\u001b[0m     chunksize\u001b[38;5;241m=\u001b[39mchunksize,\n\u001b[0;32m   3979\u001b[0m     quotechar\u001b[38;5;241m=\u001b[39mquotechar,\n\u001b[0;32m   3980\u001b[0m     date_format\u001b[38;5;241m=\u001b[39mdate_format,\n\u001b[0;32m   3981\u001b[0m     doublequote\u001b[38;5;241m=\u001b[39mdoublequote,\n\u001b[0;32m   3982\u001b[0m     escapechar\u001b[38;5;241m=\u001b[39mescapechar,\n\u001b[0;32m   3983\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39mstorage_options,\n\u001b[0;32m   3984\u001b[0m )\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\format.py:1014\u001b[0m, in \u001b[0;36mDataFrameRenderer.to_csv\u001b[1;34m(self, path_or_buf, encoding, sep, columns, index_label, mode, compression, quoting, quotechar, lineterminator, chunksize, date_format, doublequote, escapechar, errors, storage_options)\u001b[0m\n\u001b[0;32m    993\u001b[0m     created_buffer \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m    995\u001b[0m csv_formatter \u001b[38;5;241m=\u001b[39m CSVFormatter(\n\u001b[0;32m    996\u001b[0m     path_or_buf\u001b[38;5;241m=\u001b[39mpath_or_buf,\n\u001b[0;32m    997\u001b[0m     lineterminator\u001b[38;5;241m=\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   1012\u001b[0m     formatter\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfmt,\n\u001b[0;32m   1013\u001b[0m )\n\u001b[1;32m-> 1014\u001b[0m csv_formatter\u001b[38;5;241m.\u001b[39msave()\n\u001b[0;32m   1016\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m created_buffer:\n\u001b[0;32m   1017\u001b[0m     \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(path_or_buf, StringIO)\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\pandas\\io\\formats\\csvs.py:251\u001b[0m, in \u001b[0;36mCSVFormatter.save\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    247\u001b[0m \u001b[38;5;250m\u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    248\u001b[0m \u001b[38;5;124;03mCreate the writer & save.\u001b[39;00m\n\u001b[0;32m    249\u001b[0m \u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[0;32m    250\u001b[0m \u001b[38;5;66;03m# apply compression and byte/text conversion\u001b[39;00m\n\u001b[1;32m--> 251\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m get_handle(\n\u001b[0;32m    252\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfilepath_or_buffer,\n\u001b[0;32m    253\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    254\u001b[0m     encoding\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    255\u001b[0m     errors\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39merrors,\n\u001b[0;32m    256\u001b[0m     compression\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcompression,\n\u001b[0;32m    257\u001b[0m     storage_options\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstorage_options,\n\u001b[0;32m    258\u001b[0m ) \u001b[38;5;28;01mas\u001b[39;00m handles:\n\u001b[0;32m    259\u001b[0m     \u001b[38;5;66;03m# Note: self.encoding is irrelevant here\u001b[39;00m\n\u001b[0;32m    260\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mwriter \u001b[38;5;241m=\u001b[39m csvlib\u001b[38;5;241m.\u001b[39mwriter(\n\u001b[0;32m    261\u001b[0m         handles\u001b[38;5;241m.\u001b[39mhandle,\n\u001b[0;32m    262\u001b[0m         lineterminator\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlineterminator,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    267\u001b[0m         quotechar\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mquotechar,\n\u001b[0;32m    268\u001b[0m     )\n\u001b[0;32m    270\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_save()\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\anaconda3\\Lib\\site-packages\\pandas\\io\\common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[1;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[0;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[0;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[0;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[0;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[0;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[1;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(\n\u001b[0;32m    874\u001b[0m             handle,\n\u001b[0;32m    875\u001b[0m             ioargs\u001b[38;5;241m.\u001b[39mmode,\n\u001b[0;32m    876\u001b[0m             encoding\u001b[38;5;241m=\u001b[39mioargs\u001b[38;5;241m.\u001b[39mencoding,\n\u001b[0;32m    877\u001b[0m             errors\u001b[38;5;241m=\u001b[39merrors,\n\u001b[0;32m    878\u001b[0m             newline\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[0;32m    879\u001b[0m         )\n\u001b[0;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[0;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[1;31mPermissionError\u001b[0m: [Errno 13] Permission denied: './data\\\\price\\\\11_Polygon_price.csv'"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/open-interest/days\"\n",
    "params_pol = {\n",
    "    'market': 'okex', \n",
    "    'instrument': 'POL-USDT-VANILLA-PERPETUAL', \n",
    "    'groups': 'OHLC',  \n",
    "    'limit': 200,  \n",
    "    'aggregate': 1,  \n",
    "    'fill': 'true',  \n",
    "    'apply_mapping': 'true',  \n",
    "    'api_key': 'YOUR_API_KEY'  \n",
    "}\n",
    "\n",
    "response_pol = requests.get(base_url, params=params_pol)\n",
    "\n",
    "if response_pol.status_code == 200:\n",
    "    data = response_pol.json()\n",
    "\n",
    "    if 'Data' in data and isinstance(data['Data'], list):\n",
    "        data_list = data['Data']\n",
    "        \n",
    "        extracted_data = [{'timestamp': entry['TIMESTAMP'], 'price': entry['CLOSE_QUOTE']}\n",
    "                          for entry in data_list if 'TIMESTAMP' in entry and 'CLOSE_QUOTE' in entry]\n",
    "        \n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            csv_filename = os.path.join(price_folder, f\"11_Polygon_price.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(\"Data saved to 11_Polygon_price.csv\")\n",
    "        else:\n",
    "            print(\"No data available for POL-USDT on OKEx (OKX).\")\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {data}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP status code: {response_pol.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
