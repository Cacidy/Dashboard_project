{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Notice**  \n",
    "1. For data of volume, **Bitcon** data is incomplete, so we chose to eliminate the Bitcon in the volume section, and chose to plot the volume graph in the next place in the tvl order sort, i.e., the **Polygon**.  \n",
    "2. For the chainname obtained through the tvl sort is not completely correct, in the api of the fee and volume there are some chains can not get the data, we are here to eliminate these data.  \n",
    "3. We need data of 365*2+30 days (of tvl and price) to calculate the z-score to recognize abnormal values. We only plot data of 120 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name           tvl\n",
      "17   Ethereum  7.587260e+10\n",
      "47     Solana  9.273596e+09\n",
      "92       Tron  8.023196e+09\n",
      "4         BSC  5.643002e+09\n",
      "54    Bitcoin  4.827153e+09\n",
      "12       Base  3.972185e+09\n",
      "16   Arbitrum  3.324081e+09\n",
      "95        Sui  1.796125e+09\n",
      "13  Avalanche  1.568549e+09\n",
      "58      Aptos  1.233437e+09\n",
      "18    Polygon  1.175349e+09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# you can get the chain list straihgt from the API\n",
    "url = 'https://api.llama.fi/v2/chains'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200: # data was fetched successfully\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    raise Exception('Error fetching data from DeFiLlama API')\n",
    "\n",
    "dex_all_chains_url = \"https://api.llama.fi/overview/dexs?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyVolume\"\n",
    "dex_all_chains_response = requests.get(dex_all_chains_url)\n",
    "\n",
    "dex_all_chains_data = dex_all_chains_response.json()\n",
    "dex_all_chains = set(dex_all_chains_data.get('allChains', []))\n",
    "\n",
    "\n",
    "fees_all_chains_url = \"https://api.llama.fi/overview/fees?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyFees\"\n",
    "fees_all_chains_response = requests.get(fees_all_chains_url)\n",
    "\n",
    "fees_all_chains_data = fees_all_chains_response.json()\n",
    "fees_all_chains = set(fees_all_chains_data.get('allChains', []))\n",
    "\n",
    "common_chains = dex_all_chains.intersection(fees_all_chains) # get the common chains between the two sets\n",
    "\n",
    "df = df[['name', 'tvl']]\n",
    "df = df[df['name'].isin(common_chains)]\n",
    "\n",
    "# Sort the data to get the top 10 chains by TVL\n",
    "df = df.sort_values(by='tvl', ascending=False).head(11)\n",
    "print(df)\n",
    "\n",
    "# build the folder structure, update data\n",
    "base_folder = './data'\n",
    "fee_folder = os.path.join(base_folder, 'fee')\n",
    "tvl_folder = os.path.join(base_folder, 'tvl')\n",
    "volume_folder = os.path.join(base_folder, 'volume')\n",
    "price_folder = os.path.join(base_folder, 'price')\n",
    "\n",
    "for folder in [fee_folder, tvl_folder, volume_folder, price_folder]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)  # delete the folder and its contents\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_order = df['name'].tolist()\n",
    "chain_index = {chain: str(index + 1).zfill(2) for index, chain in enumerate(chain_order)}\n",
    "# give chainname an index so we can plot in order\n",
    "\n",
    "\n",
    "def fetch_historical_data(chain_name, metric):\n",
    "    if metric == 'tvl':\n",
    "        url = f'https://api.llama.fi/v2/historicalChainTvl/{chain_name}'\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)  # Directly create DataFrame from the list of dictionaries\n",
    "            df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "            csv_filename = os.path.join(tvl_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'volume':\n",
    "        url = (f'https://api.llama.fi/overview/dexs/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyVolume')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            csv_filename = os.path.join(volume_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'fee':\n",
    "        url = (f'https://api.llama.fi/overview/fees/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyFees')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            csv_filename = os.path.join(fee_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "    else:\n",
    "        raise ValueError('Invalid metric specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "# find a way to use relative path, so that the function in dynamoUtil can be run in any machine\n",
    "src_path = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common\\src'\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "USER = getpass.getuser()\n",
    "REPO_PATH = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common'\n",
    "\n",
    "sys.path.append(REPO_PATH)\n",
    "sys.path.append(REPO_PATH + '/src')\n",
    "\n",
    "from dynamoUtil import price_bar_query\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "mapping = {\n",
    "    'Ethereum': 'ETHUSDT-OKX-00000000-FUT',\n",
    "    'Tron': 'TRXUSDT-OKX-00000000-FUT',\n",
    "    'Solana': 'SOLUSDT-OKX-00000000-FUT',\n",
    "    'BSC': 'BNBUSDT-OKX-00000000-FUT',\n",
    "    'Base': 'BASEUSDT-OKX-00000000-FUT',\n",
    "    'Bitcoin': 'BTCUSDT-OKX-00000000-FUT',\n",
    "    'Arbitrum': 'ARBUSDT-OKX-00000000-FUT',\n",
    "    'Avalanche': 'AVAXUSDT-OKX-00000000-FUT',\n",
    "    'Sui': 'SUIUSDT-OKX-00000000-FUT',\n",
    "    'Aptos': 'APTUSDT-OKX-00000000-FUT',\n",
    "    'Polygon': 'MATICUSDT-OKX-00000000-FUT'\n",
    "}\n",
    "\n",
    "# give df the mapping of the code\n",
    "'''\n",
    "    这里有个问题，我用的是比较生硬的map，如果有新的chain，就需要手动添加，这个可以通过API来解决？\n",
    "'''\n",
    "\n",
    "def fetch_price_data(chain_name):\n",
    "    today = datetime.now().replace(hour=23, minute=0, second=0, microsecond=0)\n",
    "    start_date = today - timedelta(days=365*2+30)\n",
    "\n",
    "    today_str = today.strftime('%Y-%m-%d-%H-%M')\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d-%H-%M')\n",
    "    \n",
    "    instrument_code = mapping.get(chain_name)\n",
    "\n",
    "    price_data = price_bar_query(instrument_code + '|1440', start_date_str, today_str, 'live')\n",
    "    price_df = pd.DataFrame(price_data)\n",
    "    print(f\"Columns in DataFrame for {chain_name}: {price_df.columns}\") \n",
    "    print(price_df.head())\n",
    "    \n",
    "    if price_df.empty:\n",
    "        print(f\"No valid data found for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    if 'timestamp' not in price_df.columns or 'close' not in price_df.columns:\n",
    "        print(f\"Required columns 'timestamp' or 'close' not found in the data for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    selected_columns = price_df[['timestamp', 'close']].copy()\n",
    "\n",
    "    selected_columns['timestamp'] = pd.to_datetime(selected_columns['timestamp']).dt.date\n",
    "\n",
    "    selected_columns.rename(columns={'timestamp': 'date', 'close': 'price'}, inplace=True)\n",
    "\n",
    "    csv_filename = os.path.join(price_folder, f\"{chain_index[chain_name]}_{chain_name}_price.csv\")\n",
    "    # csv_filename = os.path.join(price_folder_USD, f\"{chain_index[chain_name]}_{chain_name}_price_USD.csv\")\n",
    "    selected_columns.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved price data for {chain_name} to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.For tvl we store all 11 of them.  \n",
    "2.For volume we skip Bitcoin, it's incomplete.  \n",
    "3.For fee we store all 11 of them.\n",
    "4.For price we skip Base(doesn't have coin), store POL and TRX using api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tvl data for Ethereum to ./data\\tvl\\01_Ethereum_tvl.csv\n",
      "Saved fee data for Ethereum to ./data\\fee\\01_Ethereum_fee.csv\n",
      "Saved tvl data for Solana to ./data\\tvl\\02_Solana_tvl.csv\n",
      "Saved fee data for Solana to ./data\\fee\\02_Solana_fee.csv\n",
      "Saved tvl data for Tron to ./data\\tvl\\03_Tron_tvl.csv\n",
      "Saved fee data for Tron to ./data\\fee\\03_Tron_fee.csv\n",
      "Saved tvl data for BSC to ./data\\tvl\\04_BSC_tvl.csv\n",
      "Saved fee data for BSC to ./data\\fee\\04_BSC_fee.csv\n",
      "Saved tvl data for Bitcoin to ./data\\tvl\\05_Bitcoin_tvl.csv\n",
      "Saved fee data for Bitcoin to ./data\\fee\\05_Bitcoin_fee.csv\n",
      "Saved tvl data for Base to ./data\\tvl\\06_Base_tvl.csv\n",
      "Saved fee data for Base to ./data\\fee\\06_Base_fee.csv\n",
      "Saved tvl data for Arbitrum to ./data\\tvl\\07_Arbitrum_tvl.csv\n",
      "Saved fee data for Arbitrum to ./data\\fee\\07_Arbitrum_fee.csv\n",
      "Saved tvl data for Sui to ./data\\tvl\\08_Sui_tvl.csv\n",
      "Saved fee data for Sui to ./data\\fee\\08_Sui_fee.csv\n",
      "Saved tvl data for Avalanche to ./data\\tvl\\09_Avalanche_tvl.csv\n",
      "Saved fee data for Avalanche to ./data\\fee\\09_Avalanche_fee.csv\n",
      "Saved tvl data for Aptos to ./data\\tvl\\10_Aptos_tvl.csv\n",
      "Saved fee data for Aptos to ./data\\fee\\10_Aptos_fee.csv\n",
      "Saved tvl data for Polygon to ./data\\tvl\\11_Polygon_tvl.csv\n",
      "Saved fee data for Polygon to ./data\\fee\\11_Polygon_fee.csv\n",
      "Saved volume data for Ethereum to ./data\\volume\\01_Ethereum_volume.csv\n",
      "Saved volume data for Solana to ./data\\volume\\02_Solana_volume.csv\n",
      "Saved volume data for Tron to ./data\\volume\\03_Tron_volume.csv\n",
      "Saved volume data for BSC to ./data\\volume\\04_BSC_volume.csv\n",
      "Skipping Bitcoin for volume\n",
      "Saved volume data for Base to ./data\\volume\\06_Base_volume.csv\n",
      "Saved volume data for Arbitrum to ./data\\volume\\07_Arbitrum_volume.csv\n",
      "Saved volume data for Sui to ./data\\volume\\08_Sui_volume.csv\n",
      "Saved volume data for Avalanche to ./data\\volume\\09_Avalanche_volume.csv\n",
      "Saved volume data for Aptos to ./data\\volume\\10_Aptos_volume.csv\n",
      "Saved volume data for Polygon to ./data\\volume\\11_Polygon_volume.csv\n",
      "Columns in DataFrame for Ethereum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open    volume     high    close  \\\n",
      "0     1170  1668556464865 2022-11-14  1205.53  49483570   1290.9  1244.15   \n",
      "1  1233.04  1668642771271 2022-11-15  1241.47  31102447     1290   1254.3   \n",
      "2  1185.42  1668729201093 2022-11-16  1252.39  31394991  1268.49  1215.95   \n",
      "3   1181.1  1668815611793 2022-11-17  1223.45  31155134  1228.98  1200.31   \n",
      "4  1200.35  1668902391504 2022-11-18  1216.21  20739719     1235  1213.03   \n",
      "\n",
      "                 instrument  \n",
      "0  ETHUSDT-OKX-00000000-FUT  \n",
      "1  ETHUSDT-OKX-00000000-FUT  \n",
      "2  ETHUSDT-OKX-00000000-FUT  \n",
      "3  ETHUSDT-OKX-00000000-FUT  \n",
      "4  ETHUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Ethereum to ./data\\price\\01_Ethereum_price.csv\n",
      "Columns in DataFrame for Solana: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "     low      updatedAt  timestamp   open    volume   high  close  \\\n",
      "0  11.85  1668556629236 2022-11-14  12.61  16490625  15.27  13.97   \n",
      "1  13.82  1668642936302 2022-11-15  13.92   8622213  15.14  14.29   \n",
      "2  13.61  1668729364687 2022-11-16  14.05   5347337  14.58  14.25   \n",
      "3  12.68  1668815776399 2022-11-17  14.39  13184228  14.46  13.63   \n",
      "4  12.97  1668902073258 2022-11-18  13.73   5993585   13.8  13.26   \n",
      "\n",
      "                 instrument  \n",
      "0  SOLUSDT-OKX-00000000-FUT  \n",
      "1  SOLUSDT-OKX-00000000-FUT  \n",
      "2  SOLUSDT-OKX-00000000-FUT  \n",
      "3  SOLUSDT-OKX-00000000-FUT  \n",
      "4  SOLUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Solana to ./data\\price\\02_Solana_price.csv\n",
      "Columns in DataFrame for Tron: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Tron. Skipping.\n",
      "Columns in DataFrame for BSC: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open   volume    high   close  \\\n",
      "0     240  1671925989522 2022-12-23  252.74  1655098  256.41  245.91   \n",
      "1  242.83  1672012450690 2022-12-24  245.31  1210262  245.99  244.54   \n",
      "2  240.99  1672099082999 2022-12-25  245.73  1501865  245.74  243.26   \n",
      "3     242  1672185127520 2022-12-26  242.62  1515794  245.51  244.24   \n",
      "4  242.26  1672271784814 2022-12-27  243.35  2346471  249.24  246.42   \n",
      "\n",
      "                 instrument  \n",
      "0  BNBUSDT-OKX-00000000-FUT  \n",
      "1  BNBUSDT-OKX-00000000-FUT  \n",
      "2  BNBUSDT-OKX-00000000-FUT  \n",
      "3  BNBUSDT-OKX-00000000-FUT  \n",
      "4  BNBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for BSC to ./data\\price\\04_BSC_price.csv\n",
      "Columns in DataFrame for Bitcoin: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open    volume     high    close  \\\n",
      "0  15805.6  1668556343588 2022-11-14  16263.4  18074492    17200  16619.8   \n",
      "1  16530.1  1668643133758 2022-11-15    16564  11099342  17123.5    16898   \n",
      "2  16375.3  1668729561645 2022-11-16  16785.9   8477591  17017.8  16662.5   \n",
      "3    16420  1668815974154 2022-11-17  16709.5   7283257    16750  16689.8   \n",
      "4    16555  1668902270532 2022-11-18  16946.8   6071717  16988.8  16705.1   \n",
      "\n",
      "                 instrument  \n",
      "0  BTCUSDT-OKX-00000000-FUT  \n",
      "1  BTCUSDT-OKX-00000000-FUT  \n",
      "2  BTCUSDT-OKX-00000000-FUT  \n",
      "3  BTCUSDT-OKX-00000000-FUT  \n",
      "4  BTCUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Bitcoin to ./data\\price\\05_Bitcoin_price.csv\n",
      "Columns in DataFrame for Base: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Base. Skipping.\n",
      "Columns in DataFrame for Arbitrum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open    volume    high   close  \\\n",
      "0   1.907  1709337514445 2024-02-29  1.9849   9460541  2.0959  1.9446   \n",
      "1  1.9405  1709423987133 2024-03-01  1.9764   4431391  2.0139  1.9893   \n",
      "2  1.9501  1709510224231 2024-03-02  1.9989   5307069  2.0268  2.0267   \n",
      "3  1.8044  1709596760522 2024-03-03  2.0991  12997647   2.198  2.0456   \n",
      "4  1.9201  1709682788112 2024-03-04  2.0324   7721973  2.0458   1.983   \n",
      "\n",
      "                 instrument  \n",
      "0  ARBUSDT-OKX-00000000-FUT  \n",
      "1  ARBUSDT-OKX-00000000-FUT  \n",
      "2  ARBUSDT-OKX-00000000-FUT  \n",
      "3  ARBUSDT-OKX-00000000-FUT  \n",
      "4  ARBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Arbitrum to ./data\\price\\07_Arbitrum_price.csv\n",
      "Columns in DataFrame for Sui: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open     volume    high   close  \\\n",
      "0  1.2321  1705362881490 2024-01-14  1.2687  177530154  1.3538  1.2511   \n",
      "1  1.2661  1705449301147 2024-01-15  1.2688  310876605  1.4513  1.3718   \n",
      "2  1.2396  1705535863976 2024-01-16  1.3716  198941899  1.3938  1.2706   \n",
      "3  1.1995  1705622210000 2024-01-17  1.3011  182543109  1.3291  1.2934   \n",
      "4  1.1443  1705708544738 2024-01-18   1.315  205568822  1.3482  1.1585   \n",
      "\n",
      "                 instrument  \n",
      "0  SUIUSDT-OKX-00000000-FUT  \n",
      "1  SUIUSDT-OKX-00000000-FUT  \n",
      "2  SUIUSDT-OKX-00000000-FUT  \n",
      "3  SUIUSDT-OKX-00000000-FUT  \n",
      "4  SUIUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Sui to ./data\\price\\08_Sui_price.csv\n",
      "Columns in DataFrame for Avalanche: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "     low      updatedAt  timestamp   open   volume   high  close  \\\n",
      "0  12.05  1668556761034 2022-11-14   12.7  1145366  13.61  13.13   \n",
      "1  13.03  1668643067703 2022-11-15  13.06   735078  14.02  13.53   \n",
      "2  12.81  1668729495902 2022-11-16  13.41   622147  13.73  13.06   \n",
      "3  12.66  1668815908288 2022-11-17  13.11   705877  13.36  12.88   \n",
      "4  12.89  1668902204748 2022-11-18  13.18   588856   13.3  13.01   \n",
      "\n",
      "                  instrument  \n",
      "0  AVAXUSDT-OKX-00000000-FUT  \n",
      "1  AVAXUSDT-OKX-00000000-FUT  \n",
      "2  AVAXUSDT-OKX-00000000-FUT  \n",
      "3  AVAXUSDT-OKX-00000000-FUT  \n",
      "4  AVAXUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Avalanche to ./data\\price\\09_Avalanche_price.csv\n",
      "Columns in DataFrame for Aptos: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open    volume    high   close  \\\n",
      "0  3.7619  1668556749983 2022-11-14  3.9054  13392258  4.5114  4.1921   \n",
      "1  4.1102  1668643056836 2022-11-15  4.1353  15913684  4.7199  4.3368   \n",
      "2     4.1  1668729484921 2022-11-16  4.3052  20329759  4.9679  4.4961   \n",
      "3  4.3529  1668815897187 2022-11-17   4.529  22133014  4.8432  4.6607   \n",
      "4  4.5127  1668902193882 2022-11-18   4.642  15276392  4.9337  4.7231   \n",
      "\n",
      "                 instrument  \n",
      "0  APTUSDT-OKX-00000000-FUT  \n",
      "1  APTUSDT-OKX-00000000-FUT  \n",
      "2  APTUSDT-OKX-00000000-FUT  \n",
      "3  APTUSDT-OKX-00000000-FUT  \n",
      "4  APTUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Aptos to ./data\\price\\10_Aptos_price.csv\n",
      "Columns in DataFrame for Polygon: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Polygon. Skipping.\n"
     ]
    }
   ],
   "source": [
    "for chain_name in df['name']:\n",
    "    for metric in ['tvl', 'fee']:\n",
    "        fetch_historical_data(chain_name, metric)\n",
    "        \n",
    "for chain_name in df['name']:\n",
    "    if chain_name.lower() == 'bitcoin':\n",
    "        print(f\"Skipping {chain_name} for {metric}\")\n",
    "        continue # Skip Bitcoin as its volume data is incomplete\n",
    "    metric = 'volume'\n",
    "    fetch_historical_data(chain_name, metric)\n",
    "    \n",
    "for chain_name in df['name']:\n",
    "    fetch_price_data(chain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 03_Tron_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/days\"\n",
    "params_trx = {\n",
    "    'market': 'okex', \n",
    "    'instrument': 'TRX-USDT-VANILLA-PERPETUAL', \n",
    "    'groups': 'OHLC',  \n",
    "    'limit': 365*2+30,  \n",
    "    'aggregate': 1,  \n",
    "    'fill': 'true',  \n",
    "    'apply_mapping': 'true',  \n",
    "    'api_key': 'YOUR_API_KEY'  \n",
    "}\n",
    "\n",
    "response_trx = requests.get(base_url, params=params_trx)\n",
    "\n",
    "if response_trx.status_code == 200:\n",
    "    data = response_trx.json()\n",
    "    if 'Data' in data and isinstance(data['Data'], list):\n",
    "        data_list = data['Data']\n",
    "\n",
    "        extracted_data = [{'timestamp': entry['TIMESTAMP'], 'price': entry['CLOSE']}\n",
    "                          for entry in data_list if 'TIMESTAMP' in entry and 'CLOSE' in entry]\n",
    "\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            csv_filename = os.path.join(price_folder, \"03_Tron_price.csv\")\n",
    "            df.tail(150).to_csv(csv_filename, index=False)\n",
    "            print(\"Data saved to 03_Tron_price.csv\")\n",
    "        else:\n",
    "            print(\"No data available for TRX-USDT on OKEx (OKX).\")\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {data}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP status code: {response_trx.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data entry: {'UNIT': 'DAY', 'TIMESTAMP': 1727136000, 'TYPE': '914', 'MARKET': 'okex', 'INSTRUMENT': 'POL-USDT-SWAP', 'MAPPED_INSTRUMENT': 'POL-USDT-VANILLA-PERPETUAL', 'INDEX_UNDERLYING': 'POL', 'QUOTE_CURRENCY': 'USDT', 'SETTLEMENT_CURRENCY': 'USDT', 'CONTRACT_CURRENCY': 'POL', 'DENOMINATION_TYPE': 'VANILLA', 'INDEX_UNDERLYING_ID': 10343, 'QUOTE_CURRENCY_ID': 7, 'SETTLEMENT_CURRENCY_ID': 7, 'CONTRACT_CURRENCY_ID': 10343, 'TRANSFORM_FUNCTION': '', 'OPEN': 0.417, 'HIGH': 0.417, 'LOW': 0.3905, 'CLOSE': 0.4096, 'FIRST_TRADE_TIMESTAMP': 1727166616, 'LAST_TRADE_TIMESTAMP': 1727222160, 'FIRST_TRADE_PRICE': 0.417, 'HIGH_TRADE_PRICE': 0.417, 'HIGH_TRADE_TIMESTAMP': 1727166616, 'LOW_TRADE_PRICE': 0.3905, 'LOW_TRADE_TIMESTAMP': 1727166616, 'LAST_TRADE_PRICE': 0.4096, 'TOTAL_TRADES': 5847, 'TOTAL_TRADES_BUY': 3503, 'TOTAL_TRADES_SELL': 2344, 'TOTAL_TRADES_UNKNOWN': 0, 'NUMBER_OF_CONTRACTS': 363952, 'VOLUME': 3639520, 'QUOTE_VOLUME': 1479825.706, 'VOLUME_BUY': 1766230, 'QUOTE_VOLUME_BUY': 718157.133, 'VOLUME_SELL': 1873290, 'QUOTE_VOLUME_SELL': 761668.573, 'VOLUME_UNKNOWN': 0, 'QUOTE_VOLUME_UNKNOWN': 0}\n",
      "Sample data entry: {'UNIT': 'DAY', 'TIMESTAMP': 1661472000, 'TYPE': '914', 'MARKET': 'bitmex', 'INSTRUMENT': 'MATICUSDT', 'MAPPED_INSTRUMENT': 'MATIC-USDT-VANILLA-PERPETUAL', 'INDEX_UNDERLYING': 'MATIC', 'QUOTE_CURRENCY': 'USDT', 'SETTLEMENT_CURRENCY': 'USDT', 'CONTRACT_CURRENCY': 'MATIC', 'DENOMINATION_TYPE': 'VANILLA', 'INDEX_UNDERLYING_ID': 4, 'QUOTE_CURRENCY_ID': 7, 'SETTLEMENT_CURRENCY_ID': 7, 'CONTRACT_CURRENCY_ID': 4, 'TRANSFORM_FUNCTION': '', 'OPEN': 0.8172, 'HIGH': 0.8443, 'LOW': 0.7509, 'CLOSE': 0.7641, 'FIRST_TRADE_TIMESTAMP': 1661472041, 'LAST_TRADE_TIMESTAMP': 1661558370, 'FIRST_TRADE_PRICE': 0.8152, 'HIGH_TRADE_PRICE': 0.8443, 'HIGH_TRADE_TIMESTAMP': 1661523012, 'LOW_TRADE_PRICE': 0.7509, 'LOW_TRADE_TIMESTAMP': 1661557591, 'LAST_TRADE_PRICE': 0.7641, 'TOTAL_TRADES': 1876, 'TOTAL_TRADES_BUY': 918, 'TOTAL_TRADES_SELL': 958, 'TOTAL_TRADES_UNKNOWN': 0, 'NUMBER_OF_CONTRACTS': 222540000, 'VOLUME': 2225400, 'QUOTE_VOLUME': 1786140.375, 'VOLUME_BUY': 1179220, 'QUOTE_VOLUME_BUY': 950344.263, 'VOLUME_SELL': 1046180, 'QUOTE_VOLUME_SELL': 835796.112, 'VOLUME_UNKNOWN': 0, 'QUOTE_VOLUME_UNKNOWN': 0}\n",
      "Data saved to 11_Polygon_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/days\"\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "today_timestamp = int(time.time()) \n",
    "\n",
    "params_1 = {\n",
    "    \"market\": \"okex\",\n",
    "    \"instrument\": \"POL-USDT-VANILLA-PERPETUAL\",\n",
    "    \"limit\": 365*2+30,\n",
    "    \"aggregate\": 1,\n",
    "    \"fill\": \"true\",\n",
    "    \"apply_mapping\": \"true\",\n",
    "    \"to_ts\": today_timestamp, \n",
    "    \"api_key\": api_key\n",
    "}\n",
    "\n",
    "params_2 = {\n",
    "    \"market\": \"bitmex\",\n",
    "    \"instrument\": \"MATIC-USDT-VANILLA-PERPETUAL\",\n",
    "    \"limit\": 365*2+30,\n",
    "    \"aggregate\": 1,\n",
    "    \"fill\": \"true\",\n",
    "    \"apply_mapping\": \"true\",\n",
    "    \"to_ts\": 1727062614,  \n",
    "    \"api_key\": api_key\n",
    "}\n",
    "\n",
    "def fetch_data(params):\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'Data' in data and isinstance(data['Data'], list):\n",
    "            data_list = data['Data']\n",
    "\n",
    "            if not data_list:\n",
    "                print(\"No data returned.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            print(\"Sample data entry:\", data_list[0])  \n",
    "\n",
    "            extracted_data = []\n",
    "            for entry in data_list:\n",
    "                if 'TIMESTAMP' in entry and 'CLOSE' in entry: \n",
    "                    extracted_data.append({\n",
    "                        'timestamp': entry['TIMESTAMP'], \n",
    "                        'price': entry['CLOSE']\n",
    "                    })\n",
    "                else:\n",
    "                    print(\"Missing expected fields in entry:\", entry)\n",
    "\n",
    "            if not extracted_data:\n",
    "                print(\"No valid data extracted.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            df = pd.DataFrame(extracted_data)\n",
    "\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "            df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Unexpected data format:\", data)\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. HTTP status code: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "data_1 = fetch_data(params_1)\n",
    "data_2 = fetch_data(params_2)\n",
    "\n",
    "if not data_1.empty and not data_2.empty:\n",
    "    combined_data = pd.concat([data_1, data_2]).drop_duplicates(subset=[\"date\"], keep=\"last\") # combine and remove duplicates\n",
    "    combined_data.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "    combined_data = combined_data.tail(365*2+30)\n",
    "    csv_filename = os.path.join(price_folder, f\"11_Polygon_price.csv\")\n",
    "    combined_data.to_csv(csv_filename, index=False)\n",
    "    print(\"Data saved to 11_Polygon_price.csv\")\n",
    "else:\n",
    "    print(\"Fail to fetch enough data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
