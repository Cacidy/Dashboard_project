{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import shutil\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Notice**  \n",
    "1. For data of volume, **Bitcon** data is incomplete, so we chose to eliminate the Bitcon in the volume section, and chose to plot the volume graph in the next place in the tvl order sort, i.e., the **Polygon**.  \n",
    "2. For the chainname obtained through the tvl sort is not completely correct, in the api of the fee and volume there are some chains can not get the data, we are here to eliminate these data.  \n",
    "3. We need data of 150 days to calculate the z-score to recognize abnormal values. We only plot data of 120 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name           tvl\n",
      "14   Ethereum  7.347807e+10\n",
      "91       Tron  1.368646e+10\n",
      "46     Solana  9.185863e+09\n",
      "6         BSC  5.922616e+09\n",
      "8        Base  3.766777e+09\n",
      "53    Bitcoin  3.576340e+09\n",
      "15   Arbitrum  3.233247e+09\n",
      "13  Avalanche  1.613274e+09\n",
      "94        Sui  1.555979e+09\n",
      "57      Aptos  1.266350e+09\n",
      "16    Polygon  1.183367e+09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# you can get the chain list straihgt from the API\n",
    "url = 'https://api.llama.fi/v2/chains'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200: # data was fetched successfully\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    raise Exception('Error fetching data from DeFiLlama API')\n",
    "\n",
    "dex_all_chains_url = \"https://api.llama.fi/overview/dexs?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyVolume\"\n",
    "dex_all_chains_response = requests.get(dex_all_chains_url)\n",
    "\n",
    "dex_all_chains_data = dex_all_chains_response.json()\n",
    "dex_all_chains = set(dex_all_chains_data.get('allChains', []))\n",
    "\n",
    "\n",
    "fees_all_chains_url = \"https://api.llama.fi/overview/fees?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyFees\"\n",
    "fees_all_chains_response = requests.get(fees_all_chains_url)\n",
    "\n",
    "fees_all_chains_data = fees_all_chains_response.json()\n",
    "fees_all_chains = set(fees_all_chains_data.get('allChains', []))\n",
    "\n",
    "common_chains = dex_all_chains.intersection(fees_all_chains) # get the common chains between the two sets\n",
    "\n",
    "df = df[['name', 'tvl']]\n",
    "df = df[df['name'].isin(common_chains)]\n",
    "\n",
    "# Sort the data to get the top 10 chains by TVL\n",
    "df = df.sort_values(by='tvl', ascending=False).head(11)\n",
    "print(df)\n",
    "\n",
    "base_folder = './data'\n",
    "fee_folder = os.path.join(base_folder, 'fee')\n",
    "tvl_folder = os.path.join(base_folder, 'tvl')\n",
    "volume_folder = os.path.join(base_folder, 'volume')\n",
    "\n",
    "for folder in [fee_folder, tvl_folder, volume_folder]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)  # delete the folder and its contents\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_order = df['name'].tolist()\n",
    "chain_index = {chain: str(index + 1).zfill(2) for index, chain in enumerate(chain_order)}\n",
    "# give chainname an index so we can plot in order\n",
    "\n",
    "\n",
    "def fetch_historical_data(chain_name, metric):\n",
    "    if metric == 'tvl':\n",
    "        url = f'https://api.llama.fi/v2/historicalChainTvl/{chain_name}'\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)  # Directly create DataFrame from the list of dictionaries\n",
    "            df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "            csv_filename = os.path.join(tvl_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'volume':\n",
    "        url = (f'https://api.llama.fi/overview/dexs/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyVolume')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            csv_filename = os.path.join(volume_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'fee':\n",
    "        url = (f'https://api.llama.fi/overview/fees/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyFees')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            csv_filename = os.path.join(fee_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "    else:\n",
    "        raise ValueError('Invalid metric specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tvl data for Ethereum to ./data\\tvl\\01_Ethereum_tvl.csv\n",
      "Saved fee data for Ethereum to ./data\\fee\\01_Ethereum_fee.csv\n",
      "Saved tvl data for Tron to ./data\\tvl\\02_Tron_tvl.csv\n",
      "Saved fee data for Tron to ./data\\fee\\02_Tron_fee.csv\n",
      "Saved tvl data for Solana to ./data\\tvl\\03_Solana_tvl.csv\n",
      "Saved fee data for Solana to ./data\\fee\\03_Solana_fee.csv\n",
      "Saved tvl data for BSC to ./data\\tvl\\04_BSC_tvl.csv\n",
      "Saved fee data for BSC to ./data\\fee\\04_BSC_fee.csv\n",
      "Saved tvl data for Base to ./data\\tvl\\05_Base_tvl.csv\n",
      "Saved fee data for Base to ./data\\fee\\05_Base_fee.csv\n",
      "Saved tvl data for Bitcoin to ./data\\tvl\\06_Bitcoin_tvl.csv\n",
      "Saved fee data for Bitcoin to ./data\\fee\\06_Bitcoin_fee.csv\n",
      "Saved tvl data for Arbitrum to ./data\\tvl\\07_Arbitrum_tvl.csv\n",
      "Saved fee data for Arbitrum to ./data\\fee\\07_Arbitrum_fee.csv\n",
      "Saved tvl data for Avalanche to ./data\\tvl\\08_Avalanche_tvl.csv\n",
      "Saved fee data for Avalanche to ./data\\fee\\08_Avalanche_fee.csv\n",
      "Saved tvl data for Sui to ./data\\tvl\\09_Sui_tvl.csv\n",
      "Saved fee data for Sui to ./data\\fee\\09_Sui_fee.csv\n",
      "Saved tvl data for Aptos to ./data\\tvl\\10_Aptos_tvl.csv\n",
      "Saved fee data for Aptos to ./data\\fee\\10_Aptos_fee.csv\n",
      "Saved volume data for Ethereum to ./data\\volume\\01_Ethereum_volume.csv\n",
      "Saved volume data for Tron to ./data\\volume\\02_Tron_volume.csv\n",
      "Saved volume data for Solana to ./data\\volume\\03_Solana_volume.csv\n",
      "Saved volume data for BSC to ./data\\volume\\04_BSC_volume.csv\n",
      "Saved volume data for Base to ./data\\volume\\05_Base_volume.csv\n",
      "Skipping Bitcoin for volume\n",
      "Saved volume data for Arbitrum to ./data\\volume\\07_Arbitrum_volume.csv\n",
      "Saved volume data for Avalanche to ./data\\volume\\08_Avalanche_volume.csv\n",
      "Saved volume data for Sui to ./data\\volume\\09_Sui_volume.csv\n",
      "Saved volume data for Aptos to ./data\\volume\\10_Aptos_volume.csv\n",
      "Saved volume data for Polygon to ./data\\volume\\11_Polygon_volume.csv\n"
     ]
    }
   ],
   "source": [
    "for chain_name in df['name'].head(10):\n",
    "    for metric in ['tvl', 'fee']:\n",
    "        fetch_historical_data(chain_name, metric)\n",
    "        \n",
    "for chain_name in df_volume['name']:\n",
    "    if chain_name.lower() == 'bitcoin':\n",
    "        print(f\"Skipping {chain_name} for {metric}\")\n",
    "        continue # Skip Bitcoin as its volume data is incomplete\n",
    "    metric = 'volume'\n",
    "    fetch_historical_data(chain_name, metric)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[27], line 7\u001b[0m\n\u001b[0;32m      4\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(REPO_PATH)\n\u001b[0;32m      5\u001b[0m sys\u001b[38;5;241m.\u001b[39mpath\u001b[38;5;241m.\u001b[39mappend(REPO_PATH \u001b[38;5;241m+\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/src\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdynamoUtil\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m price_bar_query\n\u001b[0;32m      9\u001b[0m price_bar \u001b[38;5;241m=\u001b[39m price_bar_query(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mETH-OKX-00000000-FUT|1\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020-10-26-07-00\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m2020-10-26-08-00\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mlive\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28mprint\u001b[39m(price_bar)\n",
      "File \u001b[1;32mc:\\Users\\YuweiCao\\Documents\\GitHub\\Project\\stable\\dynamoUtil.py:9\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mcalendar\u001b[39;00m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mboto3\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdynamodb\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mconditions\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Key, Attr\n\u001b[1;32m----> 9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mkeys\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m aws_keys \u001b[38;5;28;01mas\u001b[39;00m key\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mstatic\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m constants \u001b[38;5;28;01mas\u001b[39;00m cst\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msrc\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmapping\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m ACCOUNT_DICT\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "\n",
    "    "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
