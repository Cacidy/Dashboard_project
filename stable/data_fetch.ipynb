{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Notice**  \n",
    "1. For data of volume, **Bitcon** data is incomplete, so we chose to eliminate the Bitcon in the volume section, and chose to plot the volume graph in the next place in the tvl order sort, i.e., the **Polygon**.  \n",
    "2. For the chainname obtained through the tvl sort is not completely correct, in the api of the fee and volume there are some chains can not get the data, we are here to eliminate these data.  \n",
    "3. We need data of 150 days to calculate the z-score to recognize abnormal values. We only plot data of 120 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name           tvl\n",
      "17   Ethereum  7.604085e+10\n",
      "47     Solana  9.257967e+09\n",
      "92       Tron  9.088107e+09\n",
      "7         BSC  5.827424e+09\n",
      "9        Base  3.830352e+09\n",
      "54    Bitcoin  3.747181e+09\n",
      "16   Arbitrum  3.331686e+09\n",
      "12  Avalanche  1.596518e+09\n",
      "95        Sui  1.596115e+09\n",
      "58      Aptos  1.254248e+09\n",
      "18    Polygon  1.176373e+09\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# you can get the chain list straihgt from the API\n",
    "url = 'https://api.llama.fi/v2/chains'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200: # data was fetched successfully\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    raise Exception('Error fetching data from DeFiLlama API')\n",
    "\n",
    "dex_all_chains_url = \"https://api.llama.fi/overview/dexs?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyVolume\"\n",
    "dex_all_chains_response = requests.get(dex_all_chains_url)\n",
    "\n",
    "dex_all_chains_data = dex_all_chains_response.json()\n",
    "dex_all_chains = set(dex_all_chains_data.get('allChains', []))\n",
    "\n",
    "\n",
    "fees_all_chains_url = \"https://api.llama.fi/overview/fees?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyFees\"\n",
    "fees_all_chains_response = requests.get(fees_all_chains_url)\n",
    "\n",
    "fees_all_chains_data = fees_all_chains_response.json()\n",
    "fees_all_chains = set(fees_all_chains_data.get('allChains', []))\n",
    "\n",
    "common_chains = dex_all_chains.intersection(fees_all_chains) # get the common chains between the two sets\n",
    "\n",
    "df = df[['name', 'tvl']]\n",
    "df = df[df['name'].isin(common_chains)]\n",
    "\n",
    "# Sort the data to get the top 10 chains by TVL\n",
    "df = df.sort_values(by='tvl', ascending=False).head(11)\n",
    "print(df)\n",
    "\n",
    "base_folder = './data'\n",
    "fee_folder = os.path.join(base_folder, 'fee')\n",
    "tvl_folder = os.path.join(base_folder, 'tvl')\n",
    "volume_folder = os.path.join(base_folder, 'volume')\n",
    "price_folder = os.path.join(base_folder, 'price')\n",
    "price_folder_USD = os.path.join(base_folder, 'price_USD')\n",
    "\n",
    "for folder in [fee_folder, tvl_folder, volume_folder, price_folder, price_folder_USD]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)  # delete the folder and its contents\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_order = df['name'].tolist()\n",
    "chain_index = {chain: str(index + 1).zfill(2) for index, chain in enumerate(chain_order)}\n",
    "# give chainname an index so we can plot in order\n",
    "\n",
    "\n",
    "def fetch_historical_data(chain_name, metric):\n",
    "    if metric == 'tvl':\n",
    "        url = f'https://api.llama.fi/v2/historicalChainTvl/{chain_name}'\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)  # Directly create DataFrame from the list of dictionaries\n",
    "            df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "            csv_filename = os.path.join(tvl_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'volume':\n",
    "        url = (f'https://api.llama.fi/overview/dexs/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyVolume')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            csv_filename = os.path.join(volume_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'fee':\n",
    "        url = (f'https://api.llama.fi/overview/fees/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyFees')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(150)\n",
    "            csv_filename = os.path.join(fee_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "    else:\n",
    "        raise ValueError('Invalid metric specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "# find a way to use relative path, so that the function in dynamoUtil can be run in any machine\n",
    "src_path = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common\\src'\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "USER = getpass.getuser()\n",
    "REPO_PATH = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common'\n",
    "\n",
    "sys.path.append(REPO_PATH)\n",
    "sys.path.append(REPO_PATH + '/src')\n",
    "\n",
    "from dynamoUtil import price_bar_query\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "# mapping = {\n",
    "#     'Ethereum': 'ETHUSDT-OKX-00000000-FUT',\n",
    "#     'Tron': 'TRXUSDT-OKX-00000000-FUT',\n",
    "#     'Solana': 'SOLUSDT-OKX-00000000-FUT',\n",
    "#     'BSC': 'BNBUSDT-OKX-00000000-FUT',\n",
    "#     'Base': 'BASEUSDT-OKX-00000000-FUT',\n",
    "#     'Bitcoin': 'BTCUSDT-OKX-00000000-FUT',\n",
    "#     'Arbitrum': 'ARBUSDT-OKX-00000000-FUT',\n",
    "#     'Avalanche': 'AVAXUSDT-OKX-00000000-FUT',\n",
    "#     'Sui': 'SUIUSDT-OKX-00000000-FUT',\n",
    "#     'Aptos': 'APTUSDT-OKX-00000000-FUT',\n",
    "#     'Polygon': 'MATICUSDT-OKX-00000000-FUT'\n",
    "# }\n",
    "mapping = {\n",
    "    'Ethereum': 'ETHUSD-OKX-00000000-FUT',\n",
    "    'Tron': 'TRXUSD-OKX-00000000-FUT',\n",
    "    'Solana': 'SOLUSD-OKX-00000000-FUT',\n",
    "    'BSC': 'BNBUSD-OKX-00000000-FUT',\n",
    "    'Base': 'BASEUSD-OKX-00000000-FUT',\n",
    "    'Bitcoin': 'BTCUSD-OKX-00000000-FUT',\n",
    "    'Arbitrum': 'ARBUSD-OKX-00000000-FUT',\n",
    "    'Avalanche': 'AVAXUSD-OKX-00000000-FUT',\n",
    "    'Sui': 'SUIUSD-OKX-00000000-FUT',\n",
    "    'Aptos': 'APTUSD-OKX-00000000-FUT',\n",
    "    'Polygon': 'MATICUSD-OKX-00000000-FUT'\n",
    "}\n",
    "\n",
    "\n",
    "# give df the mapping of the code\n",
    "'''\n",
    "    这里有个问题，我用的是比较生硬的map，如果有新的chain，就需要手动添加，这个可以通过API来解决？\n",
    "'''\n",
    "\n",
    "def fetch_price_data(chain_name):\n",
    "    today = datetime.now().replace(hour=23, minute=0, second=0, microsecond=0)\n",
    "    start_date = today - timedelta(days=120)\n",
    "\n",
    "    today_str = today.strftime('%Y-%m-%d-%H-%M')\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d-%H-%M')\n",
    "    \n",
    "    instrument_code = mapping.get(chain_name)\n",
    "\n",
    "    price_data = price_bar_query(instrument_code + '|1440', start_date_str, today_str, 'live')\n",
    "    price_df = pd.DataFrame(price_data)\n",
    "    print(f\"Columns in DataFrame for {chain_name}: {price_df.columns}\") \n",
    "    print(price_df.head())\n",
    "    \n",
    "    if price_df.empty:\n",
    "        print(f\"No valid data found for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    if 'timestamp' not in price_df.columns or 'close' not in price_df.columns:\n",
    "        print(f\"Required columns 'timestamp' or 'close' not found in the data for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    selected_columns = price_df[['timestamp', 'close']].copy()\n",
    "\n",
    "    selected_columns['timestamp'] = pd.to_datetime(selected_columns['timestamp']).dt.date\n",
    "\n",
    "    selected_columns.rename(columns={'timestamp': 'date', 'close': 'price'}, inplace=True)\n",
    "\n",
    "    csv_filename = os.path.join(price_folder, f\"{chain_index[chain_name]}_{chain_name}_price.csv\")\n",
    "    # csv_filename = os.path.join(price_folder_USD, f\"{chain_index[chain_name]}_{chain_name}_price_USD.csv\")\n",
    "    selected_columns.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved price data for {chain_name} to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns in DataFrame for Ethereum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open    volume     high    close  \\\n",
      "0  2351.82  1723247965225 2024-08-08  2353.11  90893157     2727  2684.57   \n",
      "1  2553.63  1723334123101 2024-08-09  2667.34  68323488     2709     2600   \n",
      "2  2581.67  1723420695651 2024-08-10   2585.6  20589026  2643.99   2610.6   \n",
      "3  2540.31  1723507033437 2024-08-11   2625.8  48528524  2720.79  2556.59   \n",
      "4  2516.82  1723593342906 2024-08-12  2538.08  70117475  2751.99  2722.66   \n",
      "\n",
      "                instrument  \n",
      "0  ETHUSD-OKX-00000000-FUT  \n",
      "1  ETHUSD-OKX-00000000-FUT  \n",
      "2  ETHUSD-OKX-00000000-FUT  \n",
      "3  ETHUSD-OKX-00000000-FUT  \n",
      "4  ETHUSD-OKX-00000000-FUT  \n",
      "Saved price data for Ethereum to ./data\\price_USD\\01_Ethereum_price_USD.csv\n",
      "Columns in DataFrame for Solana: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open   volume    high   close  \\\n",
      "0  143.46  1723247743865 2024-08-08   144.1  8818417  163.73  163.23   \n",
      "1  150.73  1723334291540 2024-08-09  161.16  5366700  162.05  156.33   \n",
      "2  152.72  1723420474477 2024-08-10  154.95  1702602  156.58  154.04   \n",
      "3  141.07  1723506811847 2024-08-11  154.79  4135765   158.1  141.58   \n",
      "4  141.86  1723593511538 2024-08-12  142.74  4899208   150.8  146.35   \n",
      "\n",
      "                instrument  \n",
      "0  SOLUSD-OKX-00000000-FUT  \n",
      "1  SOLUSD-OKX-00000000-FUT  \n",
      "2  SOLUSD-OKX-00000000-FUT  \n",
      "3  SOLUSD-OKX-00000000-FUT  \n",
      "4  SOLUSD-OKX-00000000-FUT  \n",
      "Saved price data for Solana to ./data\\price_USD\\02_Solana_price_USD.csv\n",
      "Columns in DataFrame for Tron: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Tron. Skipping.\n",
      "Columns in DataFrame for BSC: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for BSC. Skipping.\n",
      "Columns in DataFrame for Base: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Base. Skipping.\n",
      "Columns in DataFrame for Bitcoin: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open    volume     high    close  \\\n",
      "0  55280.1  1723247817648 2024-08-08    55314  18172490  62803.2    61724   \n",
      "1  59497.9  1723334365298 2024-08-09    61244  11238205  61613.7  60868.1   \n",
      "2  60270.3  1723420548242 2024-08-10  60575.3   3930116  61225.6  60941.9   \n",
      "3  58321.4  1723506885800 2024-08-11    61114   7090683  61913.8  58732.3   \n",
      "4  57645.2  1723593585264 2024-08-12  58465.4  14269185    60726    59362   \n",
      "\n",
      "                instrument  \n",
      "0  BTCUSD-OKX-00000000-FUT  \n",
      "1  BTCUSD-OKX-00000000-FUT  \n",
      "2  BTCUSD-OKX-00000000-FUT  \n",
      "3  BTCUSD-OKX-00000000-FUT  \n",
      "4  BTCUSD-OKX-00000000-FUT  \n",
      "Saved price data for Bitcoin to ./data\\price_USD\\06_Bitcoin_price_USD.csv\n",
      "Columns in DataFrame for Arbitrum: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Arbitrum. Skipping.\n",
      "Columns in DataFrame for Avalanche: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open  volume    high   close  \\\n",
      "0  19.847  1723247796592 2024-08-08   19.85  309701    22.8  22.758   \n",
      "1  21.291  1723334344231 2024-08-09  22.671  224521  22.692  21.769   \n",
      "2  21.409  1723420527207 2024-08-10  21.595   65883  21.892  21.572   \n",
      "3  20.383  1723506864725 2024-08-11  21.638  205289  22.375  20.399   \n",
      "4  20.483  1723593564181 2024-08-12  20.529  175106   21.73  21.281   \n",
      "\n",
      "                 instrument  \n",
      "0  AVAXUSD-OKX-00000000-FUT  \n",
      "1  AVAXUSD-OKX-00000000-FUT  \n",
      "2  AVAXUSD-OKX-00000000-FUT  \n",
      "3  AVAXUSD-OKX-00000000-FUT  \n",
      "4  AVAXUSD-OKX-00000000-FUT  \n",
      "Saved price data for Avalanche to ./data\\price_USD\\08_Avalanche_price_USD.csv\n",
      "Columns in DataFrame for Sui: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Sui. Skipping.\n",
      "Columns in DataFrame for Aptos: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Aptos. Skipping.\n",
      "Columns in DataFrame for Polygon: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Polygon. Skipping.\n"
     ]
    }
   ],
   "source": [
    "# for chain_name in df['name'].head(10):\n",
    "#     for metric in ['tvl', 'fee']:\n",
    "#         fetch_historical_data(chain_name, metric)\n",
    "        \n",
    "# for chain_name in df['name']:\n",
    "#     if chain_name.lower() == 'bitcoin':\n",
    "#         print(f\"Skipping {chain_name} for {metric}\")\n",
    "#         continue # Skip Bitcoin as its volume data is incomplete\n",
    "#     metric = 'volume'\n",
    "#     fetch_historical_data(chain_name, metric)\n",
    "    \n",
    "for chain_name in df['name']:\n",
    "    fetch_price_data(chain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 02_Tron_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/open-interest/days\"\n",
    "params_trx = {\n",
    "    'market': 'okex', \n",
    "    'instrument': 'TRX-USDT-VANILLA-PERPETUAL', \n",
    "    'groups': 'OHLC',  \n",
    "    'limit': 120,  \n",
    "    'aggregate': 1,  \n",
    "    'fill': 'true',  \n",
    "    'apply_mapping': 'true',  \n",
    "    'api_key': 'YOUR_API_KEY'  \n",
    "}\n",
    "\n",
    "response_trx = requests.get(base_url, params=params_trx)\n",
    "\n",
    "if response_trx.status_code == 200:\n",
    "    data = response_trx.json()\n",
    "\n",
    "    if 'Data' in data and isinstance(data['Data'], list):\n",
    "        data_list = data['Data']\n",
    "        \n",
    "        extracted_data = [{'timestamp': entry['TIMESTAMP'], 'price': entry['CLOSE_QUOTE']}\n",
    "                          for entry in data_list if 'TIMESTAMP' in entry and 'CLOSE_QUOTE' in entry]\n",
    "        \n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            csv_filename = os.path.join(price_folder, f\"02_Tron_price.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(\"Data saved to 03_Tron_price.csv\")\n",
    "        else:\n",
    "            print(\"No data available for TRX-USDT on OKEx (OKX).\")\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {data}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP status code: {response_trx.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 11_Polygon_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/open-interest/days\"\n",
    "params_pol = {\n",
    "    'market': 'okex', \n",
    "    'instrument': 'POL-USDT-VANILLA-PERPETUAL', \n",
    "    'groups': 'OHLC',  \n",
    "    'limit': 120,  \n",
    "    'aggregate': 1,  \n",
    "    'fill': 'true',  \n",
    "    'apply_mapping': 'true',  \n",
    "    'api_key': 'YOUR_API_KEY'  \n",
    "}\n",
    "\n",
    "response_pol = requests.get(base_url, params=params_pol)\n",
    "\n",
    "if response_pol.status_code == 200:\n",
    "    data = response_pol.json()\n",
    "\n",
    "    if 'Data' in data and isinstance(data['Data'], list):\n",
    "        data_list = data['Data']\n",
    "        \n",
    "        extracted_data = [{'timestamp': entry['TIMESTAMP'], 'price': entry['CLOSE_QUOTE']}\n",
    "                          for entry in data_list if 'TIMESTAMP' in entry and 'CLOSE_QUOTE' in entry]\n",
    "        \n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            csv_filename = os.path.join(price_folder, f\"11_Polygon_price.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(\"Data saved to 11_Polygon_price.csv\")\n",
    "        else:\n",
    "            print(\"No data available for POL-USDT on OKEx (OKX).\")\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {data}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP status code: {response_pol.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
