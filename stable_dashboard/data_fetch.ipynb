{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "import shutil\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### **Notice**  \n",
    "1. For data of volume, **Bitcon** data is incomplete, so we chose to eliminate the Bitcon in the volume section, and chose to plot the volume graph in the next place in the tvl order sort, i.e., the **Polygon**.  \n",
    "2. For the chainname obtained through the tvl sort is not completely correct, in the api of the fee and volume there are some chains can not get the data, we are here to eliminate these data.  \n",
    "3. We need data of 365*2+30 days (of tvl and price) to calculate the z-score to recognize abnormal values. We only plot data of 120 days."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "         name           tvl\n",
      "16   Ethereum  7.180617e+10\n",
      "47     Solana  8.736776e+09\n",
      "92       Tron  7.465960e+09\n",
      "54    Bitcoin  6.945383e+09\n",
      "10        BSC  5.664515e+09\n",
      "11       Base  3.715635e+09\n",
      "18   Arbitrum  3.193690e+09\n",
      "95        Sui  1.695768e+09\n",
      "13  Avalanche  1.449431e+09\n",
      "17    Polygon  1.156530e+09\n",
      "59      Aptos  1.144239e+09\n"
     ]
    }
   ],
   "source": [
    "# you can get the chain list straihgt from the API\n",
    "url = 'https://api.llama.fi/v2/chains'\n",
    "response = requests.get(url)\n",
    "if response.status_code == 200: # data was fetched successfully\n",
    "    data = response.json()\n",
    "    df = pd.DataFrame(data)\n",
    "else:\n",
    "    raise Exception('Error fetching data from DeFiLlama API')\n",
    "\n",
    "dex_all_chains_url = \"https://api.llama.fi/overview/dexs?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyVolume\"\n",
    "dex_all_chains_response = requests.get(dex_all_chains_url)\n",
    "\n",
    "dex_all_chains_data = dex_all_chains_response.json()\n",
    "dex_all_chains = set(dex_all_chains_data.get('allChains', []))\n",
    "\n",
    "\n",
    "fees_all_chains_url = \"https://api.llama.fi/overview/fees?excludeTotalDataChart=true&excludeTotalDataChartBreakdown=true&dataType=dailyFees\"\n",
    "fees_all_chains_response = requests.get(fees_all_chains_url)\n",
    "\n",
    "fees_all_chains_data = fees_all_chains_response.json()\n",
    "fees_all_chains = set(fees_all_chains_data.get('allChains', []))\n",
    "\n",
    "common_chains = dex_all_chains.intersection(fees_all_chains) # get the common chains between the two sets\n",
    "\n",
    "df = df[['name', 'tvl']]\n",
    "df = df[df['name'].isin(common_chains)]\n",
    "\n",
    "# Sort the data to get the top 10 chains by TVL\n",
    "df = df.sort_values(by='tvl', ascending=False).head(11)\n",
    "print(df)\n",
    "\n",
    "# build the folder structure, update data\n",
    "base_folder = './data'\n",
    "fee_folder = os.path.join(base_folder, 'fee')\n",
    "tvl_folder = os.path.join(base_folder, 'tvl')\n",
    "volume_folder = os.path.join(base_folder, 'volume')\n",
    "price_folder = os.path.join(base_folder, 'price')\n",
    "\n",
    "for folder in [fee_folder, tvl_folder, volume_folder, price_folder]:\n",
    "    if os.path.exists(folder):\n",
    "        shutil.rmtree(folder)  # delete the folder and its contents\n",
    "    os.makedirs(folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "chain_order = df['name'].tolist()\n",
    "chain_index = {chain: str(index + 1).zfill(2) for index, chain in enumerate(chain_order)}\n",
    "# give chainname an index so we can plot in order\n",
    "\n",
    "\n",
    "def fetch_historical_data(chain_name, metric):\n",
    "    if metric == 'tvl':\n",
    "        url = f'https://api.llama.fi/v2/historicalChainTvl/{chain_name}'\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data)  # Directly create DataFrame from the list of dictionaries\n",
    "            df['date'] = pd.to_datetime(df['date'], unit='s')\n",
    "            csv_filename = os.path.join(tvl_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'volume':\n",
    "        url = (f'https://api.llama.fi/overview/dexs/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyVolume')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            csv_filename = os.path.join(volume_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "        \n",
    "    elif metric == 'fee':\n",
    "        url = (f'https://api.llama.fi/overview/fees/{chain_name}'\n",
    "                  '?excludeTotalDataChart=false'\n",
    "                  '&excludeTotalDataChartBreakdown=true'\n",
    "                  '&dataType=dailyFees')\n",
    "        response = requests.get(url)\n",
    "        if response.status_code == 200:\n",
    "            data = response.json()\n",
    "            df = pd.DataFrame(data['totalDataChart'], columns=['timestamp', metric])   \n",
    "            df['date'] = pd.to_datetime(df['timestamp'], unit='s')\n",
    "            df = df.sort_values(by='date')\n",
    "            df = df[['date', metric]].tail(365*2+30)\n",
    "            csv_filename = os.path.join(fee_folder, f\"{chain_index[chain_name]}_{chain_name}_{metric}.csv\")\n",
    "            df.to_csv(csv_filename, index=False)\n",
    "            print(f\"Saved {metric} data for {chain_name} to {csv_filename}\")\n",
    "        else:\n",
    "            raise Exception(f'Error fetching historical {metric} data for {chain_name}')\n",
    "    else:\n",
    "        raise ValueError('Invalid metric specified')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import getpass\n",
    "# find a way to use relative path, so that the function in dynamoUtil can be run in any machine\n",
    "src_path = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common\\src'\n",
    "\n",
    "if src_path not in sys.path:\n",
    "    sys.path.append(src_path)\n",
    "\n",
    "USER = getpass.getuser()\n",
    "REPO_PATH = r'C:\\Users\\YuweiCao\\Documents\\GitHub\\char-python-common'\n",
    "\n",
    "sys.path.append(REPO_PATH)\n",
    "sys.path.append(REPO_PATH + '/src')\n",
    "\n",
    "from dynamoUtil import price_bar_query\n",
    "from datetime import datetime, timedelta\n",
    "\n",
    "mapping = {\n",
    "    'Ethereum': 'ETHUSDT-OKX-00000000-FUT',\n",
    "    'Tron': 'TRXUSDT-OKX-00000000-FUT',\n",
    "    'Solana': 'SOLUSDT-OKX-00000000-FUT',\n",
    "    'BSC': 'BNBUSDT-OKX-00000000-FUT',\n",
    "    'Base': 'BASEUSDT-OKX-00000000-FUT',\n",
    "    'Bitcoin': 'BTCUSDT-OKX-00000000-FUT',\n",
    "    'Arbitrum': 'ARBUSDT-OKX-00000000-FUT',\n",
    "    'Avalanche': 'AVAXUSDT-OKX-00000000-FUT',\n",
    "    'Sui': 'SUIUSDT-OKX-00000000-FUT',\n",
    "    'Aptos': 'APTUSDT-OKX-00000000-FUT',\n",
    "    'Polygon': 'MATICUSDT-OKX-00000000-FUT'\n",
    "}\n",
    "\n",
    "# give df the mapping of the code\n",
    "'''\n",
    "    直接用map list对应不知道会不会有问题\n",
    "'''\n",
    "\n",
    "def fetch_price_data(chain_name):\n",
    "    today = datetime.now().replace(hour=23, minute=0, second=0, microsecond=0)\n",
    "    start_date = today - timedelta(days=365*2+30)\n",
    "\n",
    "    today_str = today.strftime('%Y-%m-%d-%H-%M')\n",
    "    start_date_str = start_date.strftime('%Y-%m-%d-%H-%M')\n",
    "    \n",
    "    instrument_code = mapping.get(chain_name)\n",
    "\n",
    "    price_data = price_bar_query(instrument_code + '|1440', start_date_str, today_str, 'live')\n",
    "    price_df = pd.DataFrame(price_data)\n",
    "    print(f\"Columns in DataFrame for {chain_name}: {price_df.columns}\") \n",
    "    print(price_df.head())\n",
    "    \n",
    "    if price_df.empty:\n",
    "        print(f\"No valid data found for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    if 'timestamp' not in price_df.columns or 'close' not in price_df.columns:\n",
    "        print(f\"Required columns 'timestamp' or 'close' not found in the data for {chain_name}. Skipping.\")\n",
    "        return\n",
    "\n",
    "    selected_columns = price_df[['timestamp', 'close']].copy()\n",
    "\n",
    "    selected_columns['timestamp'] = pd.to_datetime(selected_columns['timestamp']).dt.date\n",
    "\n",
    "    selected_columns.rename(columns={'timestamp': 'date', 'close': 'price'}, inplace=True)\n",
    "\n",
    "    csv_filename = os.path.join(price_folder, f\"{chain_index[chain_name]}_{chain_name}_price.csv\")\n",
    "    # csv_filename = os.path.join(price_folder_USD, f\"{chain_index[chain_name]}_{chain_name}_price_USD.csv\")\n",
    "    selected_columns.to_csv(csv_filename, index=False)\n",
    "    print(f\"Saved price data for {chain_name} to {csv_filename}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1.For tvl we store all 11 of them.  \n",
    "2.For volume we skip Bitcoin, it's incomplete.  \n",
    "3.For fee we store all 11 of them.\n",
    "4.For price we skip Base(doesn't have coin), store POL and TRX using api."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved tvl data for Ethereum to ./data\\tvl\\01_Ethereum_tvl.csv\n",
      "Saved fee data for Ethereum to ./data\\fee\\01_Ethereum_fee.csv\n",
      "Saved tvl data for Solana to ./data\\tvl\\02_Solana_tvl.csv\n",
      "Saved fee data for Solana to ./data\\fee\\02_Solana_fee.csv\n",
      "Saved tvl data for Tron to ./data\\tvl\\03_Tron_tvl.csv\n",
      "Saved fee data for Tron to ./data\\fee\\03_Tron_fee.csv\n",
      "Saved tvl data for Bitcoin to ./data\\tvl\\04_Bitcoin_tvl.csv\n",
      "Saved fee data for Bitcoin to ./data\\fee\\04_Bitcoin_fee.csv\n",
      "Saved tvl data for BSC to ./data\\tvl\\05_BSC_tvl.csv\n",
      "Saved fee data for BSC to ./data\\fee\\05_BSC_fee.csv\n",
      "Saved tvl data for Base to ./data\\tvl\\06_Base_tvl.csv\n",
      "Saved fee data for Base to ./data\\fee\\06_Base_fee.csv\n",
      "Saved tvl data for Arbitrum to ./data\\tvl\\07_Arbitrum_tvl.csv\n",
      "Saved fee data for Arbitrum to ./data\\fee\\07_Arbitrum_fee.csv\n",
      "Saved tvl data for Sui to ./data\\tvl\\08_Sui_tvl.csv\n",
      "Saved fee data for Sui to ./data\\fee\\08_Sui_fee.csv\n",
      "Saved tvl data for Avalanche to ./data\\tvl\\09_Avalanche_tvl.csv\n",
      "Saved fee data for Avalanche to ./data\\fee\\09_Avalanche_fee.csv\n",
      "Saved tvl data for Polygon to ./data\\tvl\\10_Polygon_tvl.csv\n",
      "Saved fee data for Polygon to ./data\\fee\\10_Polygon_fee.csv\n",
      "Saved tvl data for Aptos to ./data\\tvl\\11_Aptos_tvl.csv\n",
      "Saved fee data for Aptos to ./data\\fee\\11_Aptos_fee.csv\n",
      "Saved volume data for Ethereum to ./data\\volume\\01_Ethereum_volume.csv\n",
      "Saved volume data for Solana to ./data\\volume\\02_Solana_volume.csv\n",
      "Saved volume data for Tron to ./data\\volume\\03_Tron_volume.csv\n",
      "Skipping Bitcoin for volume\n",
      "Saved volume data for BSC to ./data\\volume\\05_BSC_volume.csv\n",
      "Saved volume data for Base to ./data\\volume\\06_Base_volume.csv\n",
      "Saved volume data for Arbitrum to ./data\\volume\\07_Arbitrum_volume.csv\n",
      "Saved volume data for Sui to ./data\\volume\\08_Sui_volume.csv\n",
      "Saved volume data for Avalanche to ./data\\volume\\09_Avalanche_volume.csv\n",
      "Saved volume data for Polygon to ./data\\volume\\10_Polygon_volume.csv\n",
      "Saved volume data for Aptos to ./data\\volume\\11_Aptos_volume.csv\n",
      "Columns in DataFrame for Ethereum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open    volume     high    close  \\\n",
      "0   1078.2  1669161249514 2022-11-21  1140.89  48191112     1148  1107.25   \n",
      "1  1072.45  1669247905888 2022-11-22  1106.88  40048819  1142.86  1139.13   \n",
      "2  1127.11  1669334259732 2022-11-23  1134.15  35853278  1191.63  1184.37   \n",
      "3  1180.58  1669420571251 2022-11-24  1181.62  28742857   1217.6  1203.07   \n",
      "4  1168.13  1669506970007 2022-11-25  1194.34  24973788  1209.53  1198.75   \n",
      "\n",
      "                 instrument  \n",
      "0  ETHUSDT-OKX-00000000-FUT  \n",
      "1  ETHUSDT-OKX-00000000-FUT  \n",
      "2  ETHUSDT-OKX-00000000-FUT  \n",
      "3  ETHUSDT-OKX-00000000-FUT  \n",
      "4  ETHUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Ethereum to ./data\\price\\01_Ethereum_price.csv\n",
      "Columns in DataFrame for Solana: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "     low      updatedAt  timestamp   open    volume   high  close  \\\n",
      "0  11.25  1669161413670 2022-11-21  12.25  11323859  12.25  11.83   \n",
      "1   10.9  1669247588051 2022-11-22  11.78   9759895  12.51  12.44   \n",
      "2  12.52  1669333939502 2022-11-23   12.6  14339244  14.75  14.35   \n",
      "3  13.82  1669420736394 2022-11-24  14.12  11395942  14.95  14.61   \n",
      "4  13.89  1669507133812 2022-11-25  14.16   5898925   14.5  14.02   \n",
      "\n",
      "                 instrument  \n",
      "0  SOLUSDT-OKX-00000000-FUT  \n",
      "1  SOLUSDT-OKX-00000000-FUT  \n",
      "2  SOLUSDT-OKX-00000000-FUT  \n",
      "3  SOLUSDT-OKX-00000000-FUT  \n",
      "4  SOLUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Solana to ./data\\price\\02_Solana_price.csv\n",
      "Columns in DataFrame for Tron: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Tron. Skipping.\n",
      "Columns in DataFrame for Bitcoin: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "       low      updatedAt  timestamp     open    volume     high    close  \\\n",
      "0  15438.8  1669161129115 2022-11-21  16272.1  12880851  16332.3    15782   \n",
      "1  15629.8  1669247785602 2022-11-22  15872.2   9882221  16326.9  16229.3   \n",
      "2  16168.8  1669334138459 2022-11-23    16187  10608899  16743.7    16606   \n",
      "3  16462.3  1669420449694 2022-11-24  16562.4   7205909  16813.3    16607   \n",
      "4    16350  1669506850078 2022-11-25  16530.6   5660628  16632.2  16523.9   \n",
      "\n",
      "                 instrument  \n",
      "0  BTCUSDT-OKX-00000000-FUT  \n",
      "1  BTCUSDT-OKX-00000000-FUT  \n",
      "2  BTCUSDT-OKX-00000000-FUT  \n",
      "3  BTCUSDT-OKX-00000000-FUT  \n",
      "4  BTCUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Bitcoin to ./data\\price\\04_Bitcoin_price.csv\n",
      "Columns in DataFrame for BSC: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open   volume    high   close  \\\n",
      "0     240  1671925989522 2022-12-23  252.74  1655098  256.41  245.91   \n",
      "1  242.83  1672012450690 2022-12-24  245.31  1210262  245.99  244.54   \n",
      "2  240.99  1672099082999 2022-12-25  245.73  1501865  245.74  243.26   \n",
      "3     242  1672185127520 2022-12-26  242.62  1515794  245.51  244.24   \n",
      "4  242.26  1672271784814 2022-12-27  243.35  2346471  249.24  246.42   \n",
      "\n",
      "                 instrument  \n",
      "0  BNBUSDT-OKX-00000000-FUT  \n",
      "1  BNBUSDT-OKX-00000000-FUT  \n",
      "2  BNBUSDT-OKX-00000000-FUT  \n",
      "3  BNBUSDT-OKX-00000000-FUT  \n",
      "4  BNBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for BSC to ./data\\price\\05_BSC_price.csv\n",
      "Columns in DataFrame for Base: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Base. Skipping.\n",
      "Columns in DataFrame for Arbitrum: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open    volume    high   close  \\\n",
      "0   1.907  1709337514445 2024-02-29  1.9849   9460541  2.0959  1.9446   \n",
      "1  1.9405  1709423987133 2024-03-01  1.9764   4431391  2.0139  1.9893   \n",
      "2  1.9501  1709510224231 2024-03-02  1.9989   5307069  2.0268  2.0267   \n",
      "3  1.8044  1709596760522 2024-03-03  2.0991  12997647   2.198  2.0456   \n",
      "4  1.9201  1709682788112 2024-03-04  2.0324   7721973  2.0458   1.983   \n",
      "\n",
      "                 instrument  \n",
      "0  ARBUSDT-OKX-00000000-FUT  \n",
      "1  ARBUSDT-OKX-00000000-FUT  \n",
      "2  ARBUSDT-OKX-00000000-FUT  \n",
      "3  ARBUSDT-OKX-00000000-FUT  \n",
      "4  ARBUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Arbitrum to ./data\\price\\07_Arbitrum_price.csv\n",
      "Columns in DataFrame for Sui: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open     volume    high   close  \\\n",
      "0  1.2321  1705362881490 2024-01-14  1.2687  177530154  1.3538  1.2511   \n",
      "1  1.2661  1705449301147 2024-01-15  1.2688  310876605  1.4513  1.3718   \n",
      "2  1.2396  1705535863976 2024-01-16  1.3716  198941899  1.3938  1.2706   \n",
      "3  1.1995  1705622210000 2024-01-17  1.3011  182543109  1.3291  1.2934   \n",
      "4  1.1443  1705708544738 2024-01-18   1.315  205568822  1.3482  1.1585   \n",
      "\n",
      "                 instrument  \n",
      "0  SUIUSDT-OKX-00000000-FUT  \n",
      "1  SUIUSDT-OKX-00000000-FUT  \n",
      "2  SUIUSDT-OKX-00000000-FUT  \n",
      "3  SUIUSDT-OKX-00000000-FUT  \n",
      "4  SUIUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Sui to ./data\\price\\08_Sui_price.csv\n",
      "Columns in DataFrame for Avalanche: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "     low      updatedAt  timestamp   open  volume   high  close  \\\n",
      "0  11.55  1669161545325 2022-11-21  12.11  826767  12.16   11.8   \n",
      "1  11.42  1669247720021 2022-11-22  11.93  883759  12.37  12.34   \n",
      "2  12.41  1669334071865 2022-11-23  12.44  731356  13.07  13.06   \n",
      "3  12.75  1669420383566 2022-11-24  12.96  557318   13.4  12.96   \n",
      "4  12.53  1669506784695 2022-11-25  12.83  417116  13.03  12.82   \n",
      "\n",
      "                  instrument  \n",
      "0  AVAXUSDT-OKX-00000000-FUT  \n",
      "1  AVAXUSDT-OKX-00000000-FUT  \n",
      "2  AVAXUSDT-OKX-00000000-FUT  \n",
      "3  AVAXUSDT-OKX-00000000-FUT  \n",
      "4  AVAXUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Avalanche to ./data\\price\\09_Avalanche_price.csv\n",
      "Columns in DataFrame for Polygon: RangeIndex(start=0, stop=0, step=1)\n",
      "Empty DataFrame\n",
      "Columns: []\n",
      "Index: []\n",
      "No valid data found for Polygon. Skipping.\n",
      "Columns in DataFrame for Aptos: Index(['low', 'updatedAt', 'timestamp', 'open', 'volume', 'high', 'close',\n",
      "       'instrument'],\n",
      "      dtype='object')\n",
      "      low      updatedAt  timestamp    open    volume    high   close  \\\n",
      "0   3.865  1669161534141 2022-11-21  4.0727  10424848  4.1545  4.0638   \n",
      "1  3.8517  1669247709077 2022-11-22  4.0641  11278009  4.5366  4.3137   \n",
      "2  4.2436  1669334060904 2022-11-23  4.2948   9468599  4.6051  4.4414   \n",
      "3  4.2103  1669420372538 2022-11-24  4.4095  11955012    4.73    4.44   \n",
      "4  4.2556  1669506773696 2022-11-25  4.3526   8295973  4.5583  4.4282   \n",
      "\n",
      "                 instrument  \n",
      "0  APTUSDT-OKX-00000000-FUT  \n",
      "1  APTUSDT-OKX-00000000-FUT  \n",
      "2  APTUSDT-OKX-00000000-FUT  \n",
      "3  APTUSDT-OKX-00000000-FUT  \n",
      "4  APTUSDT-OKX-00000000-FUT  \n",
      "Saved price data for Aptos to ./data\\price\\11_Aptos_price.csv\n"
     ]
    }
   ],
   "source": [
    "for chain_name in df['name']:\n",
    "    for metric in ['tvl', 'fee']:\n",
    "        fetch_historical_data(chain_name, metric)\n",
    "        \n",
    "for chain_name in df['name']:\n",
    "    if chain_name.lower() == 'bitcoin':\n",
    "        print(f\"Skipping {chain_name} for {metric}\")\n",
    "        continue # Skip Bitcoin as its volume data is incomplete\n",
    "    metric = 'volume'\n",
    "    fetch_historical_data(chain_name, metric)\n",
    "    \n",
    "for chain_name in df['name']:\n",
    "    fetch_price_data(chain_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data saved to 03_Tron_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/days\"\n",
    "params_trx = {\n",
    "    'market': 'okex', \n",
    "    'instrument': 'TRX-USDT-VANILLA-PERPETUAL', \n",
    "    'groups': 'OHLC',  \n",
    "    'limit': 365*2+30,  \n",
    "    'aggregate': 1,  \n",
    "    'fill': 'true',  \n",
    "    'apply_mapping': 'true',  \n",
    "    'api_key': 'YOUR_API_KEY'  \n",
    "}\n",
    "\n",
    "response_trx = requests.get(base_url, params=params_trx)\n",
    "\n",
    "if response_trx.status_code == 200:\n",
    "    data = response_trx.json()\n",
    "    if 'Data' in data and isinstance(data['Data'], list):\n",
    "        data_list = data['Data']\n",
    "\n",
    "        extracted_data = [{'timestamp': entry['TIMESTAMP'], 'price': entry['CLOSE']}\n",
    "                          for entry in data_list if 'TIMESTAMP' in entry and 'CLOSE' in entry]\n",
    "\n",
    "        df = pd.DataFrame(extracted_data)\n",
    "\n",
    "        df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "        df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "        if not df.empty:\n",
    "            csv_filename = os.path.join(price_folder, \"03_Tron_price.csv\")\n",
    "            df.tail(150).to_csv(csv_filename, index=False)\n",
    "            print(\"Data saved to 03_Tron_price.csv\")\n",
    "        else:\n",
    "            print(\"No data available for TRX-USDT on OKEx (OKX).\")\n",
    "    else:\n",
    "        print(f\"Unexpected data format: {data}\")\n",
    "else:\n",
    "    print(f\"Failed to fetch data. HTTP status code: {response_trx.status_code}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample data entry: {'UNIT': 'DAY', 'TIMESTAMP': 1727136000, 'TYPE': '914', 'MARKET': 'okex', 'INSTRUMENT': 'POL-USDT-SWAP', 'MAPPED_INSTRUMENT': 'POL-USDT-VANILLA-PERPETUAL', 'INDEX_UNDERLYING': 'POL', 'QUOTE_CURRENCY': 'USDT', 'SETTLEMENT_CURRENCY': 'USDT', 'CONTRACT_CURRENCY': 'POL', 'DENOMINATION_TYPE': 'VANILLA', 'INDEX_UNDERLYING_ID': 10343, 'QUOTE_CURRENCY_ID': 7, 'SETTLEMENT_CURRENCY_ID': 7, 'CONTRACT_CURRENCY_ID': 10343, 'TRANSFORM_FUNCTION': '', 'OPEN': 0.417, 'HIGH': 0.417, 'LOW': 0.3905, 'CLOSE': 0.4096, 'FIRST_TRADE_TIMESTAMP': 1727166616, 'LAST_TRADE_TIMESTAMP': 1727222160, 'FIRST_TRADE_PRICE': 0.417, 'HIGH_TRADE_PRICE': 0.417, 'HIGH_TRADE_TIMESTAMP': 1727166616, 'LOW_TRADE_PRICE': 0.3905, 'LOW_TRADE_TIMESTAMP': 1727166616, 'LAST_TRADE_PRICE': 0.4096, 'TOTAL_TRADES': 5847, 'TOTAL_TRADES_BUY': 3503, 'TOTAL_TRADES_SELL': 2344, 'TOTAL_TRADES_UNKNOWN': 0, 'NUMBER_OF_CONTRACTS': 363952, 'VOLUME': 3639520, 'QUOTE_VOLUME': 1479825.706, 'VOLUME_BUY': 1766230, 'QUOTE_VOLUME_BUY': 718157.133, 'VOLUME_SELL': 1873290, 'QUOTE_VOLUME_SELL': 761668.573, 'VOLUME_UNKNOWN': 0, 'QUOTE_VOLUME_UNKNOWN': 0}\n",
      "Sample data entry: {'UNIT': 'DAY', 'TIMESTAMP': 1661472000, 'TYPE': '914', 'MARKET': 'bitmex', 'INSTRUMENT': 'MATICUSDT', 'MAPPED_INSTRUMENT': 'MATIC-USDT-VANILLA-PERPETUAL', 'INDEX_UNDERLYING': 'MATIC', 'QUOTE_CURRENCY': 'USDT', 'SETTLEMENT_CURRENCY': 'USDT', 'CONTRACT_CURRENCY': 'MATIC', 'DENOMINATION_TYPE': 'VANILLA', 'INDEX_UNDERLYING_ID': 4, 'QUOTE_CURRENCY_ID': 7, 'SETTLEMENT_CURRENCY_ID': 7, 'CONTRACT_CURRENCY_ID': 4, 'TRANSFORM_FUNCTION': '', 'OPEN': 0.8172, 'HIGH': 0.8443, 'LOW': 0.7509, 'CLOSE': 0.7641, 'FIRST_TRADE_TIMESTAMP': 1661472041, 'LAST_TRADE_TIMESTAMP': 1661558370, 'FIRST_TRADE_PRICE': 0.8152, 'HIGH_TRADE_PRICE': 0.8443, 'HIGH_TRADE_TIMESTAMP': 1661523012, 'LOW_TRADE_PRICE': 0.7509, 'LOW_TRADE_TIMESTAMP': 1661557591, 'LAST_TRADE_PRICE': 0.7641, 'TOTAL_TRADES': 1876, 'TOTAL_TRADES_BUY': 918, 'TOTAL_TRADES_SELL': 958, 'TOTAL_TRADES_UNKNOWN': 0, 'NUMBER_OF_CONTRACTS': 222540000, 'VOLUME': 2225400, 'QUOTE_VOLUME': 1786140.375, 'VOLUME_BUY': 1179220, 'QUOTE_VOLUME_BUY': 950344.263, 'VOLUME_SELL': 1046180, 'QUOTE_VOLUME_SELL': 835796.112, 'VOLUME_UNKNOWN': 0, 'QUOTE_VOLUME_UNKNOWN': 0}\n",
      "Data saved to 11_Polygon_price.csv\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://data-api.cryptocompare.com/futures/v1/historical/days\"\n",
    "api_key = \"YOUR_API_KEY\"\n",
    "\n",
    "today_timestamp = int(time.time()) \n",
    "\n",
    "params_1 = {\n",
    "    \"market\": \"okex\",\n",
    "    \"instrument\": \"POL-USDT-VANILLA-PERPETUAL\",\n",
    "    \"limit\": 365*2+30,\n",
    "    \"aggregate\": 1,\n",
    "    \"fill\": \"true\",\n",
    "    \"apply_mapping\": \"true\",\n",
    "    \"to_ts\": today_timestamp, \n",
    "    \"api_key\": api_key\n",
    "}\n",
    "\n",
    "params_2 = {\n",
    "    \"market\": \"bitmex\",\n",
    "    \"instrument\": \"MATIC-USDT-VANILLA-PERPETUAL\",\n",
    "    \"limit\": 365*2+30,\n",
    "    \"aggregate\": 1,\n",
    "    \"fill\": \"true\",\n",
    "    \"apply_mapping\": \"true\",\n",
    "    \"to_ts\": 1727062614,  \n",
    "    \"api_key\": api_key\n",
    "}\n",
    "\n",
    "def fetch_data(params):\n",
    "    response = requests.get(base_url, params=params)\n",
    "    if response.status_code == 200:\n",
    "        data = response.json()\n",
    "        if 'Data' in data and isinstance(data['Data'], list):\n",
    "            data_list = data['Data']\n",
    "\n",
    "            if not data_list:\n",
    "                print(\"No data returned.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            print(\"Sample data entry:\", data_list[0])  \n",
    "\n",
    "            extracted_data = []\n",
    "            for entry in data_list:\n",
    "                if 'TIMESTAMP' in entry and 'CLOSE' in entry: \n",
    "                    extracted_data.append({\n",
    "                        'timestamp': entry['TIMESTAMP'], \n",
    "                        'price': entry['CLOSE']\n",
    "                    })\n",
    "                else:\n",
    "                    print(\"Missing expected fields in entry:\", entry)\n",
    "\n",
    "            if not extracted_data:\n",
    "                print(\"No valid data extracted.\")\n",
    "                return pd.DataFrame()\n",
    "\n",
    "            df = pd.DataFrame(extracted_data)\n",
    "\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], unit='s').dt.date\n",
    "\n",
    "            df.rename(columns={'timestamp': 'date'}, inplace=True)\n",
    "\n",
    "            return df\n",
    "        else:\n",
    "            print(\"Unexpected data format:\", data)\n",
    "            return pd.DataFrame()\n",
    "    else:\n",
    "        print(f\"Failed to fetch data. HTTP status code: {response.status_code}\")\n",
    "        return pd.DataFrame()\n",
    "    \n",
    "data_1 = fetch_data(params_1)\n",
    "data_2 = fetch_data(params_2)\n",
    "\n",
    "if not data_1.empty and not data_2.empty:\n",
    "    combined_data = pd.concat([data_1, data_2]).drop_duplicates(subset=[\"date\"], keep=\"last\") # combine and remove duplicates\n",
    "    combined_data.sort_values(by=\"date\", inplace=True)\n",
    "\n",
    "    combined_data = combined_data.tail(365*2+30)\n",
    "    csv_filename = os.path.join(price_folder, f\"11_Polygon_price.csv\")\n",
    "    combined_data.to_csv(csv_filename, index=False)\n",
    "    print(\"Data saved to 11_Polygon_price.csv\")\n",
    "else:\n",
    "    print(\"Fail to fetch enough data.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
